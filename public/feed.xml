<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tensorflow Internal</title>
  <subtitle>All about tensorflow</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="https://deeptensorflow.github.io/"/>
  <updated>2017-02-28T02:54:57.000Z</updated>
  <id>https://deeptensorflow.github.io/</id>
  
  <author>
    <name>MyeongsooKim</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>초보자를 위한 MNIST(텐서플로우)</title>
    <link href="https://deeptensorflow.github.io/2017/02/28/mnist-for-beginners/"/>
    <id>https://deeptensorflow.github.io/2017/02/28/mnist-for-beginners/</id>
    <published>2017-02-28T00:17:40.000Z</published>
    <updated>2017-02-28T02:54:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>이 글은 <a href="https://www.tensorflow.org/get_started/mnist/beginners" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/get_started/mnist/beginners</a> 공식 홈페이지 내용을 번역한 것이 주 내용입니다.</p>
<h1 id="MNIST란-무엇일까"><a href="#MNIST란-무엇일까" class="headerlink" title="MNIST란 무엇일까?"></a>MNIST란 무엇일까?</h1><p>MNIST란 본래 미국에서 우편번호를 분류할때 기계에게 분류를 맡기려는 시도에서 비롯되었습니다.<br>MNIST는 간단한 컴퓨터 시각 데이터 세트입니다.<br>이것은 다음과 같은 자필 자릿수의 이미지로 구성됩니다.<br><img src="https://deeptensorflow.github.io/images/mnist.png" alt="MNIST"><br>또한 각 이미지의 레이블을 포함하여 어떤 숫자인지 알려줍니다.<br>예를 들어 위 이미지의 레이블은 5, 0, 4 및 1입니다.<br>이 자습서에서는 이미지를보고 어떤 자릿수인지 예측하는 모델을 교육 할 것입니다.<br>우리의 목표는 최첨단 성능을 구현하는 매우 정교한 모델을 교육하는 것이 아닙니다.<br>우리는 Softmax Regression이라 불리는 매우 간단한 모델로 시작할 것입니다.<br>이 자습서의 실제 코드는 매우 짧으며 모든 흥미로운 내용은 단 3 줄에서 발생합니다.<br>그러나 TensorFlow가 작동하는 방법과 핵심 기계 학습 개념 모두에 대한 아이디어를 이해하는 것이 매우 중요합니다.</p>
<p>이 튜토리얼에서 우리가 달성 할 수있는 것 :</p>
<ul>
<li><p>MNIST 데이터와 softmax 회귀에 대해 알게 될 것입니다.</p>
</li>
<li><p>이미지의 모든 픽셀을 보면서 숫자를 인식하는 모델 인 함수를 만들 것입니다.</p>
</li>
<li><p>TensorFlow를 사용하여 수천 가지 예제를 “훑어보고”숫자를 인식하도록 모델을 교육합니다(첫 번째 TensorFlow 세션을 실행하여 수행).</p>
</li>
<li><p>테스트 데이터로 모델의 정확성을 확인할 것입니다.</p>
</li>
</ul>
<p>MNIST 데이터는 Yann LeCun의 웹 사이트 에서 호스팅됩니다.<br>이 자습서의 코드를 복사하여 붙여 넣는 경우 다음 두 줄의 코드를 사용하여 데이터를 자동으로 다운로드하고 읽습니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</div></pre></td></tr></table></figure>
<p>MNIST 데이터는 훈련 데이터(mnist.train) 55,000개, 테스트 데이터(mnist.test) 10,000개, 및 검증 데이터(mnist.validation) 5,000개 세 부분으로 나누어집니다.<br>이 분할은 매우 중요하며 기계 학습에서 필수적입니다.<br>이미 트레이닝을 한 데이터에 대해서 검증을 하고 테스트를 하는 것은 의미가 없겠죠?<br>꼭 나누어주세요!<br>MNIST데이터는 두가지로 분류되어 있습니다.<br>손으로 직접 쓴 글씨와 그에 해당하는 라벨 데이터로 나누어져 있습니다.<br>트레이닝 이미지는 mnist.train.images이고 트레이닝 레이블은 mnist.train.labels입니다.<br>트레이닝 세트와 테스트 세트에는 이미지와 해당 레이블이 포함되어 있습니다.<br><img src="https://deeptensorflow.github.io/images/mnistmatrix.png" alt="mnistmatrix"><br>이 배열을 28x28 = 784 숫자의 벡터로 전개 할 수 있습니다.<br>이 배열을 1열로 펼친다면 784개의 숫자로 이루어진 데이터가 되겠죠?<br>55000개의 데이터를 테스트 데이터로 쓸 때 [55000,784] 배열꼴의 데이터를 쓴다면 MNIST데이터 55000의 데이터를 모을 수 있는 꼴이 될 것입니다.<br>첫 번째 차원은 이미지 목록에 대한 인덱스이고 두 번째 차원은 각 이미지의 각 픽셀에 대한 인덱스입니다.<br><img src="https://deeptensorflow.github.io/images/mnisttrainxs.png" alt="mnist데이터셋행렬"><br>MNIST의 각 이미지에는 이미지에 그려지는 숫자를 나타내는 0에서 9 사이의 숫자가 해당 레이블을 가지고 있습니다.<br>이 튜토리얼의 목적을 위해 우리는 레이블을 “원 핫 벡터 (one-hot vectors)”로 할 것입니다.<br>원 핫 벡터는 대부분 차원에서 0이고 단일 차원에서 1 인 벡터입니다.<br>이 경우,n번째 자릿수는 n차원 벡터로 표현됩니다.<br>예를 들어, 3은 [0,0,0,1,0,0,0,0,0,0] 입니다.<br>자, 이제 softmax를 통해서 분석할 일만 남았습니다.</p>
<h1 id="softmax란"><a href="#softmax란" class="headerlink" title="softmax란?"></a>softmax란?</h1><p> 우리는 이미지를보고 각 숫자가 될 확률을 줄 수 있기를 원합니다.<br> 예를 들어, 우리 모델은 9의 그림을보고 80%의 확률로 9라고 확신 할 수 있지만, 다른 모든 것들에도 약간의 확률이 있습니다(합계 20%).<br> 100% 확실하지는 않습니다.<br> 이렇게 각 숫자에 대한 확률로 나타내주는 쉬운 방법이 softmax 회귀분석을 쓰는 방법입니다.<br> Softmax 회귀 분석을 하는 과정을 아래에서 보여드리겠습니다.<br> 우선 [55000, 784] 행렬의 데이터가 들어올 것입니다(55000개의 MNIST데이터셋).<br> 그리고 이 데이터셋은 [784,10]꼴의 행렬과 곱해지게 될 것입니다(weight의 개념으로).<br> 그리고는 [10]꼴의 행렬과 더해질 것입니다(bias의 개념으로).<br> 그러면 각 데이터셋에 대해서 [10]꼴의 배열에 임의의 숫자가 나오겠지요?<br> 그것을 softmax로 처리하면 각각 10개의 데이터가 0~1사이의 데이터로 변합니다.<br> 그 10개의 데이터값을 다 합한뒤 각각의 데이터에 나누어준다면 그것이 확률이 되는 것입니다.<br> <img src="https://deeptensorflow.github.io/images/tf_softmax.png" alt="softmax"></p>
<h1 id="텐서플로우를-이용해-MNIST를-분석해보자"><a href="#텐서플로우를-이용해-MNIST를-분석해보자" class="headerlink" title="텐서플로우를 이용해 MNIST를 분석해보자!"></a>텐서플로우를 이용해 MNIST를 분석해보자!</h1><p>이전의 포스팅에서 설명드렸던 placeholder를 이용해 값을 유동적으로 받기 위한 x를 선언하겠습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, [None, 784])</div></pre></td></tr></table></figure></p>
<p>위의 코드에서 None에는 데이터의 개수가 올 것입니다.</p>
<p>그리고 위에서 설명한대로 softmax를 정의하기 위해서 [784,10] 꼴의 weight와 [10]꼴의 bias가 필요합니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W = tf.Variable(tf.zeros([784,10]))</div><div class="line">b = tf.Variable(tf.zeros([10]))</div></pre></td></tr></table></figure></p>
<p>그럼 이제 x값에 weight와 bias를 더하고 softmax를 취해줘야겠죠?<br>텐서플로우에서는 이것이 한줄로 가능합니다.</p>
<p>자, 이제 데이터를 받고 softmax를 적용시킬 준비가 끝났습니다.</p>
<h1 id="트레이닝-시키기"><a href="#트레이닝-시키기" class="headerlink" title="트레이닝 시키기"></a>트레이닝 시키기</h1><p>우리는 우선 트레이닝을 시키기 위해서 손실함수를 작성해야합니다.<br>이는 모델이 원하는 결과와 얼마나 멀리 떨어져 있는지 나타냅니다.<br>우리는 손실함수를 최소화하려고 노력하며, 손실함수 마진이 작을수록 모델이 더 좋습니다.<br>어렵게 생각하지 마세요!<br>손실함수는 그냥 실제 값과 우리의 예측값이 얼마나 다른지 알 수 있게 해주는 함수입니다.<br>여기서는 인기있는 손실함수인 cross-entropy라는 것을 써보겠습니다.<br>자세한 것은 모르셔도 되고 그냥 실제 값과 예측 값의 차이를 표현하는 한 방식이라고 보시면 됩니다.<br>y 값은 예측 값입니다.<br>y_ 값이 실제 값입니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">y = tf.nn.softmax(tf.matmul(x,W)+b)</div><div class="line">y_ = tf.placeholder(tf.float32, [None, 10])</div><div class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1]))</div></pre></td></tr></table></figure></p>
<p>그런 다음 이 손실함수를 통해서 예측값과 실제값의 차이를 알았으니 차이를 좁혀주기 위해서 학습을 시켜야겠지요?<br>GradientDescentOptimizer 라는 기본적인 알고리즘으로 학습을 시켜보겠습니다.<br>마찬가지로 이 알고리즘이 어떤식으로 동작하는지 모르더라도 텐서플로우에서 제공하는 API를 쓰면 손쉽게 적용할 수 있습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</div></pre></td></tr></table></figure></p>
<p>이제 반복문으로 이 트레인함수를 돌려주면 됩니다.<br>mnist.train.next<em>batch는 텐서플로우에서 제공해주는 기본 API입니다.<br>데이터를 100개씩 랜덤으로 뽑아줍니다.<br>그리고 placeholder로 x와 y</em>를 선언했기 때문에 데이터를 읽어서 바로 x와 y_에 넣어줄 수 있습니다.<br>그런뒤 위의 손실함수를 GradientDescentOptimizer로 최소화시켜주는 것입니다(train).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sess = tf.InteractiveSession()</div><div class="line">tf.global_variables_initializer().run()</div><div class="line"></div><div class="line">for _ in range(1000):</div><div class="line">    batch_xs, batch_ys = mnist.train.next_batch(100)</div><div class="line">    sess.run(train, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</div></pre></td></tr></table></figure></p>
<h1 id="모델-평가하기"><a href="#모델-평가하기" class="headerlink" title="모델 평가하기"></a>모델 평가하기</h1><p>자, 이렇게 훈련시킨 모델이 얼마나 잘 학습되었는지 확인해봐야겠죠?<br>softmax를 거친 우리 기대값 배열은 0~9사이의 숫자가 나올 확률을 계산해 두었을 것입니다.<br>그렇다면 확률이 가장 높게 나온 label이 우리의 예측 숫자가 될 것입니다.<br>테스트 데이터를 넣고 정확도를 평균내어봅시다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</div><div class="line"></div><div class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</div></pre></td></tr></table></figure></p>
<p>정확도가 몇퍼센트가 나오시나요?<br>제 코드를 기준으로는 91.4프로가 나옵니다.<br>다음에는 이 정확도를 99프로 이상으로 끌어올려보도록 하겠습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;이 글은 &lt;a href=&quot;https://www.tensorflow.org/get_started/mnist/beginners&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https:/
    
    </summary>
    
      <category term="TensorFlow" scheme="https://deeptensorflow.github.io/categories/TensorFlow/"/>
    
      <category term="App" scheme="https://deeptensorflow.github.io/categories/TensorFlow/App/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="MNIST" scheme="https://deeptensorflow.github.io/tags/MNIST/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 맛보기(기본 가이드)</title>
    <link href="https://deeptensorflow.github.io/2017/02/27/tensorflow-tasting/"/>
    <id>https://deeptensorflow.github.io/2017/02/27/tensorflow-tasting/</id>
    <published>2017-02-26T23:35:14.000Z</published>
    <updated>2017-02-27T12:20:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>이 문서는 <a href="https://www.tensorflow.org/get_started/get_started" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/get_started/get_started</a> 의 내용을 번역했습니다.</p>
<h1 id="텐서플로우를-하기-전에-알아야-할것"><a href="#텐서플로우를-하기-전에-알아야-할것" class="headerlink" title="텐서플로우를 하기 전에 알아야 할것"></a>텐서플로우를 하기 전에 알아야 할것</h1><ol>
<li>파이썬 프로그래밍</li>
<li>배열에 관한 내용 (조금이라도)</li>
<li>머신러닝에 관한 내용 (조금이라도)</li>
</ol>
<p>참고로 파이썬은 <a href="https://wikidocs.net/book/1" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/book/1</a> 이곳에서 공부하시는 것을 추천드립니다.<br>TensorFlow는 여러 API를 제공합니다.<br>최저 수준의 API 인 TensorFlow Core는 완벽한 프로그래밍 제어 기능을 제공합니다.<br>TensorFlow Core는 기계 학습 연구자 및 모델을 정밀하게 제어해야하는 사람들에게 권장됩니다.<br>높은 수준의 API는 TensorFlow Core 위에 구축됩니다.<br>이러한 상위 수준의 API는 일반적으로 TensorFlow Core보다 배우고 사용하기가 쉽습니다.<br>또한 상위 수준의 API는 반복적인 작업을 여러 사용자간에 보다 쉽고 일관되게 만듭니다.<br>tf.contrib.learn과 같은 고급 API를 사용하면 데이터 세트, 견적 도구, 교육 및 추론을 관리 할 수 ​​있습니다.<br>상위 수준 TensorFlow API 중 일부 (메소드 이름이 포함 contrib)는 아직 개발 중입니다.<br>contrib이후의 TensorFlow 릴리스에서 일부 메서드가 변경되거나 더 이상 사용되지 않을 수도 있습니다.</p>
<h1 id="텐서란"><a href="#텐서란" class="headerlink" title="텐서란?"></a>텐서란?</h1><p>TensorFlow에서 데이터의 중심 단위는 텐서 입니다.<br>텐서는 임의의 수의 차원으로 배열된 값들의 집합으로 구성됩니다.<br>텐서의 랭크는 차원의 개수입니다.<br>다음은 텐서(tensors)의 몇 가지 예입니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">3 # a rank 0 tensor; this is a scalar with shape []</div><div class="line">[1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3]</div><div class="line">[[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3]</div><div class="line">[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]</div></pre></td></tr></table></figure></p>
<h1 id="텐서플로우-CORE"><a href="#텐서플로우-CORE" class="headerlink" title="텐서플로우 CORE"></a>텐서플로우 CORE</h1><ul>
<li>텐서플로우 가져오기</li>
</ul>
<p>TensorFlow 프로그램에 대한 표준 import 문은 다음과 같습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div></pre></td></tr></table></figure></p>
<p>이렇게하면 파이썬은 TensorFlow의 모든 클래스, 메소드 및 심볼에 액세스 할 수 있습니다.<br>대부분의 문서에서는 이미 이 작업을 수행했다고 가정합니다.</p>
<ul>
<li>연산 그래프</li>
</ul>
<p>TensorFlow Core 프로그램은 두 개의 개별 섹션으로 구성되어 있다고 생각할 수 있습니다.</p>
<ol>
<li>연산 그래프 작성.</li>
<li>연산 그래프를 실행합니다.<br>연산 그래프는 노드의 그래프로 배열 TensorFlow의 일련의 동작입니다.<br>간단한 전산 그래프를 작성해 봅시다.<br>각 노드는 0개 이상의 텐서를 입력으로 사용하고 출력으로도 생성합니다.<br>상수도 노드중 하나의 유형입니다.<br>TensorFlow 상수는 input과 output이 없으며 내부적으로 저장하는 값을 출력합니다.<br>node1과 node2라는 두개의 텐서를 만들어보겠습니다.<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">node1 = tf.constant(3.0, tf.float32)</div><div class="line">node2 = tf.constant(4.0) # also tf.float32 implicitly</div><div class="line">print(node1, node2)</div></pre></td></tr></table></figure>
</li>
</ol>
<p>결과는 아래와 같습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32)</div></pre></td></tr></table></figure></p>
<p>우리의 예상과는 다른 결과가 나왔습니다.<br>3.0과 4.0이 나올줄 알았는데 이상한 상태를 가르키는듯한 문구만 나왔습니다.<br>우리가 원하는 값을 출력하려면 세션을 주고 실행을 시켜야 합니다.<br>아래의 내용을 추가해봅시다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line">print(sess.run([node1, node2]))</div></pre></td></tr></table></figure></p>
<p>Tensor노드를 연산과 결합 하여보다 복잡한 계산을 할 수 있습니다 (연산도 노드입니다).<br>예를 들어 두 개의 상수 노드를 추가하고 다음과 같이 새 그래프를 생성 할 수 있습니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">node3 = tf.add(node1, node2)</div><div class="line">print(&quot;node3: &quot;, node3)</div><div class="line">print(&quot;sess.run(node3): &quot;,sess.run(node3))</div></pre></td></tr></table></figure>
<p>출력 결과값은 아래와 같습니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node3:  Tensor(&quot;Add_2:0&quot;, shape=(), dtype=float32)</div><div class="line">sess.run(node3):  7.0</div></pre></td></tr></table></figure>
<ul>
<li>텐서보드</li>
</ul>
<p>TensorFlow는 전산 그래프의 그림을 표시 할 수있는 TensorBoard라는 유틸리티를 제공합니다.<br>다음은 TensorBoard가 그래프를 시각화하는 방법을 보여주는 스크린 샷입니다.<br><img src="https://deeptensorflow.github.io/images/tfboardex1.png" alt="텐서플로우보드"><br>데이터가 많아지면 일일히 정보를 확인하는 것이 어려울 수 있습니다.<br>텐서보드를 이용하면 원하는 데이터를 한눈에 볼 수 있습니다.</p>
<ul>
<li>placeholder</li>
</ul>
<p>placeholder는 나중에 값을 채워주겠다고 하고 우선 형식만 선언해 두는 형태입니다.<br>아래와 같이 연산을 지정해 준 뒤에 feed_dict 매개 변수를 사용하여 이러한 입력란에 구체적인 값을 제공하는 Tensors를 지정하여 이 그래프를 여러 입력으로 평가할 수 있습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">a = tf.placeholder(tf.float32)</div><div class="line">b = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">tf_add = a + b</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line"></div><div class="line">print(sess.run(tf_add, feed_dict= &#123;a : [1,2], b: [3,4]&#125;))</div></pre></td></tr></table></figure></p>
<ul>
<li>학습 시키기</li>
</ul>
<p>머신러닝 라이브러리인 만큼 당연히 모델을 만들고 학습을 시킬 수 있는 방법도 제공하고 있습니다.<br>모델을 학습 가능하게 만들려면 동일한 입력으로 새로운 출력을 얻기 위해 그래프를 수정할 수 있어야합니다.<br>변수를 사용하면 그래프에 학습 가능한 매개 변수를 추가 할 수 있습니다.<br>그것들은 타입과 초기 값으로 구성됩니다.</p>
<p>우선 처음에는 아래와 같이 평가 모델을 작성합니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">W = tf.Variable([.3], tf.float32)</div><div class="line">b = tf.Variable([.3], tf.float32)</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line"></div><div class="line">Y = W * x + b</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">print(sess.run(Y, feed_dict= &#123;x : [1., 2., 3., 4.]&#125;))</div></pre></td></tr></table></figure></p>
<p>상수는 호출 할 때 초기화되며 tf.constant값은 절대로 변경 될 수 없습니다.<br>반대로 변수(tf.Variable)는 초기화 할 때 초기화되지 않습니다.<br>TensorFlow 프로그램의 모든 변수를 초기화하려면 다음과 같이 명시적으로 특수 작업(tf.global_variables_initializer())을 호출해야합니다.</p>
<p>우리는 모델을 만들었지만 아직 얼마나 좋은지 모릅니다.<br>교육 데이터에 대한 모델을 평가하려면 원하는 값을 제공하기 위한 목표값이 필요하며 손실 함수를 작성해야합니다.<br>손실 함수는 목표값으로부터 현재 모델이 얼마나 떨어져 있는지를 측정합니다.<br>현재 모델과 목표값 사이의 델타의 제곱을 합한 선형 회귀에 표준 손실 모델을 사용합니다.<br>즉, 기대값과 목표값의 차를 제곱한 값을 손실 모델로 작성합니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">W = tf.Variable([.3], tf.float32)</div><div class="line">b = tf.Variable([.3], tf.float32)</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32)</div><div class="line">_y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">Y = W * x + b</div><div class="line">loss = tf.reduce_sum(tf.square(Y-_y))</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">print(sess.run(loss, feed_dict= &#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;))</div></pre></td></tr></table></figure></p>
<p>우리는 tf.assign을 통해 tf.Variable로 선언된 변수에 대해서 수동으로 값을 바꾸어 줄 수 있습니다.<br>예를들어 위의 모델은 W가 -1, b가 1 일때 손실 함수가 0이 되어 최적의 매개변수가 됩니다.<br>아래와 같이 모델을 작성할 수 있습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">W = tf.Variable([.3], tf.float32)</div><div class="line">b = tf.Variable([.3], tf.float32)</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32)</div><div class="line">_y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">Y = W * x + b</div><div class="line">loss = tf.reduce_sum(tf.square(Y-_y))</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">fixW = tf.assign(W, [-1])</div><div class="line">fixb = tf.assign(b, [1])</div><div class="line"></div><div class="line">sess.run([fixW, fixb])</div><div class="line"></div><div class="line">print(sess.run(loss, feed_dict= &#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;))</div></pre></td></tr></table></figure></p>
<p>print값은 0이 됩니다.<br>우리는 Wand 의 “완벽한”값을 추측 b했지만 기계 학습의 요점은 올바른 모델 매개 변수를 자동으로 찾는 것입니다.<br>다음 섹션에서 이를 수행하는 방법을 보여줄 것입니다.</p>
<ul>
<li>트레이닝 시키기</li>
</ul>
<p>텐서플로우에서는 손실함수의 값을 최소화 시키기 위해서 여러 optimizer들을 제공합니다.<br>이들을 간단한 API로 손실함수를 최소화 시킵니다.<br>가장 간단한 예는 gradient descent optimizer입니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">W = tf.Variable([.3], tf.float32)</div><div class="line">b = tf.Variable([.3], tf.float32)</div><div class="line"></div><div class="line">x = tf.placeholder(tf.float32)</div><div class="line">_y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line">Y = W * x + b</div><div class="line">loss = tf.reduce_sum(tf.square(Y-_y))</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(0.01)</div><div class="line">train = optimizer.minimize(loss)</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for i in range(1000):</div><div class="line">    sess.run(train, feed_dict=&#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;)</div><div class="line"></div><div class="line">print(sess.run([W, b]))</div></pre></td></tr></table></figure></p>
<p>위와 같은 방법으로 자동으로 W, b를 학습시킬 수 있습니다.</p>
<h1 id="tf-contrib-learn"><a href="#tf-contrib-learn" class="headerlink" title="tf.contrib.learn"></a>tf.contrib.learn</h1><p>tf.contrib.learn는 기계 학습의 메커니즘을 단순화하는 고급 TensorFlow 라이브러리입니다.<br>평가관련 반복문 관리, 트레이닝 관련 반복문 관리, 데이터셋 관리, feeding관리를 포함합니다.<br>tf.contrib.learn은 많은 공통 모델을 정의합니다.</p>
<p>linear regression코드에 이를 적용하면 아래와 같이 간결해집니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"># NumPy is often used to load, manipulate and preprocess data.</div><div class="line">import numpy as np</div><div class="line"></div><div class="line"># Declare list of features. We only have one real-valued feature. There are many</div><div class="line"># other types of columns that are more complicated and useful.</div><div class="line">features = [tf.contrib.layers.real_valued_column(&quot;x&quot;, dimension=1)]</div><div class="line"></div><div class="line"># An estimator is the front end to invoke training (fitting) and evaluation</div><div class="line"># (inference). There are many predefined types like linear regression,</div><div class="line"># logistic regression, linear classification, logistic classification, and</div><div class="line"># many neural network classifiers and regressors. The following code</div><div class="line"># provides an estimator that does linear regression.</div><div class="line">estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)</div><div class="line"></div><div class="line"># TensorFlow provides many helper methods to read and set up data sets.</div><div class="line"># Here we use `numpy_input_fn`. We have to tell the function how many batches</div><div class="line"># of data (num_epochs) we want and how big each batch should be.</div><div class="line">x = np.array([1., 2., 3., 4.])</div><div class="line">y = np.array([0., -1., -2., -3.])</div><div class="line">input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;&quot;x&quot;:x&#125;, y, batch_size=4,</div><div class="line">                                              num_epochs=1000)</div><div class="line"></div><div class="line"># We can invoke 1000 training steps by invoking the `fit` method and passing the</div><div class="line"># training data set.</div><div class="line">estimator.fit(input_fn=input_fn, steps=1000)</div><div class="line"></div><div class="line"># Here we evaluate how well our model did. In a real example, we would want</div><div class="line"># to use a separate validation and testing data set to avoid overfitting.</div><div class="line">estimator.evaluate(input_fn=input_fn)</div></pre></td></tr></table></figure></p>
<h1 id="커스텀모델-만들기"><a href="#커스텀모델-만들기" class="headerlink" title="커스텀모델 만들기"></a>커스텀모델 만들기</h1><p>tf.contrib.learn는 함수정의부분을 수정할 수 있습니다.<br>TensorFlow에 내장되어 있지 않은 커스텀 모델을 만들고 싶다고 가정 해 보겠습니다.<br>우리는 여전히 높은 수준의 반복문 관리, 트레이닝 관련 반복문 관리, 데이터셋 관리, feeding관리를 유지할 수 있습니다.<br>설명을 위해, 우리는 저수준 TensorFlow API에 대한 지식을 사용하여 LinearRegressor에 대한 자체 모델을 구현하는 방법을 보여줄 것입니다.<br>tf.contrib.learn.Estimator를 써서 개발해 보도록 하겠습니다.<br>tf.contrib.learn.LinearRegressor는 tf.contrib.learn.Estimator의 sub-class입니다.<br>Estimator에게 예측, 교육 단계 및 손실을 평가할 수있는 방법을 tf.contrib.learn에 알리는 function_fn이라는 기능을 제공하기 만하면됩니다.<br>아래의 코드가 그 예제입니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">import numpy as np</div><div class="line">import tensorflow as tf</div><div class="line"># Declare list of features, we only have one real-valued feature</div><div class="line">def model(features, labels, mode):</div><div class="line">  # Build a linear model and predict values</div><div class="line">  W = tf.get_variable(&quot;W&quot;, [1], dtype=tf.float64)</div><div class="line">  b = tf.get_variable(&quot;b&quot;, [1], dtype=tf.float64)</div><div class="line">  y = W*features[&apos;x&apos;] + b</div><div class="line">  # Loss sub-graph</div><div class="line">  loss = tf.reduce_sum(tf.square(y - labels))</div><div class="line">  # Training sub-graph</div><div class="line">  global_step = tf.train.get_global_step()</div><div class="line">  optimizer = tf.train.GradientDescentOptimizer(0.01)</div><div class="line">  train = tf.group(optimizer.minimize(loss),</div><div class="line">                   tf.assign_add(global_step, 1))</div><div class="line">  # ModelFnOps connects subgraphs we built to the</div><div class="line">  # appropriate functionality.</div><div class="line">  return tf.contrib.learn.ModelFnOps(</div><div class="line">      mode=mode, predictions=y,</div><div class="line">      loss= loss,</div><div class="line">      train_op=train)</div><div class="line"></div><div class="line">estimator = tf.contrib.learn.Estimator(model_fn=model)</div><div class="line"># define our data set</div><div class="line">x=np.array([1., 2., 3., 4.])</div><div class="line">y=np.array([0., -1., -2., -3.])</div><div class="line">input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;&quot;x&quot;: x&#125;, y, 4, num_epochs=1000)</div><div class="line"></div><div class="line"># train</div><div class="line">estimator.fit(input_fn=input_fn, steps=1000)</div><div class="line"># evaluate our model</div><div class="line">print(estimator.evaluate(input_fn=input_fn, steps=10))</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;이 문서는 &lt;a href=&quot;https://www.tensorflow.org/get_started/get_started&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://ww
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="App" scheme="https://deeptensorflow.github.io/categories/Tensorflow/App/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우에 새로운 연산 추가하기(커스터마이징)</title>
    <link href="https://deeptensorflow.github.io/2017/02/21/add-new-operation-on-tensorflow/"/>
    <id>https://deeptensorflow.github.io/2017/02/21/add-new-operation-on-tensorflow/</id>
    <published>2017-02-21T13:24:53.000Z</published>
    <updated>2017-02-23T20:02:39.000Z</updated>
    
    <content type="html"><![CDATA[<p>텐서플로우를 이용해서 소스코드를 작성하다보면 가끔 내가 만든 연산을 추가하고 싶다는 생각이 듭니다.<br>이럴 경우에 텐서플로우에서는 operation을 추가하는 방법을 공식홈페이지에서 설명해주고 있습니다.<br><a href="https://www.tensorflow.org/extend/adding_an_op" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/extend/adding_an_op</a><br>하지만 영어로 되어있기에… 개인 저장용으로 operation을 텐서플로우에 추가하는 방법을 적어보고자 합니다.</p>
<h1 id="operation-추가하기"><a href="#operation-추가하기" class="headerlink" title="operation 추가하기"></a>operation 추가하기</h1><p>기존 TensorFlow 라이브러리에서 다루지 않는 연산을 만들려면 먼저 파이썬에서 연산을 기존 파이썬 연산이나 함수의 조합으로 작성하는 것이 좋습니다.<br>이것이 가능하지 않으면 사용자 정의 C ++ op를 작성할 수 있습니다.<br>사용자 정의 C ++ 연산을 작성하는 데에는 여러 가지 이유가 있습니다.</p>
<ul>
<li>기존 작업의 구성으로 작업을 표현하는 것이 쉽지 않거나 가능하지 않은 경우</li>
<li>기존 기본 요소의 구성으로 작업을 표현하는 것은 효율적이지 않은 경우</li>
<li>원래 있던 기존의 요소들을 미래의 컴파일러가 융합하기 힘들어하는 경우<br>즉, 왠만하면 기존의 텐서플로우 op로 연산을 하되 기존의 op로 연산이 불가능하거나 효율적이지 않은 경우 본인의 op를 직접 추가하라는 말입니다.</li>
</ul>
<p>맞춤 작업을 통합하려면 다음 작업이 필요합니다.</p>
<ol>
<li>새로운 op를 C ++ 파일로 등록하십시오. Op 등록은 op의 구현과 독립적인 op 기능을위한 인터페이스를 정의합니다. 예를 들어 op 등록은 op의 이름과 op의 입력과 출력을 정의합니다. 또한 텐서의 모양을 정의합니다.</li>
<li>C ++로 op의 실제 동작을 구현하십시오. op의 구현은 커널로 알려져 있으며 1 단계에서 등록한 인터페이스의 구체적인 구현입니다.(실제 연산을 정의하라는 말) 다양한 입/출력 유형 또는 아키텍처 (예 : CPU, GPU)에 대해 여러 개의 커널이있을 수 있습니다.</li>
<li>Python 래퍼를 만듭니다 (선택 사항). 이 래퍼는 Python에서 op를 만드는 데 사용되는 공용 API입니다. op 등록에서 기본 래퍼가 생성됩니다.이 래퍼는 직접 사용하거나 추가 할 수 있습니다.</li>
<li>op (옵션)의 gradient를 계산하는 함수를 작성합니다.</li>
<li>op를 테스트하십시오. 우리는 대개 편의상 Python에서 이 작업을 수행하지만 C++로 op를 테스트 할 수도 있습니다. Gradient를 정의하면 파이썬 gradient checker로 확인할 수 있습니다. relu_op_test.pyRelu를 보면 Relu-like operators의 forward함수와 그들의 gradient를 확인할 수 있습니다.</li>
</ol>
<h1 id="op의-인터페이스-정의"><a href="#op의-인터페이스-정의" class="headerlink" title="op의 인터페이스 정의"></a>op의 인터페이스 정의</h1><p>op의 인터페이스는 TensorFlow 시스템에 등록하여 정의합니다.<br>등록시 op의 이름, 입력 (유형 및 이름) 및 출력 (유형 및 이름)과 op가 필요할 수 있는 docstrings 및 attrs를 지정합니다.<br>이것이 어떻게 작동 하는지를보기 위해 예시를 들어보겠습니다.<br>int32 형태의 첫 번째 요소를 제외한 모든 요소가 0으로 되는 텐서 복사본을 출력 하는 op를 만들고 싶다고 가정합니다.<br>이렇게하려면 명명 된 파일을 만듭니다 zero_out.cc.<br>그런 다음 REGISTER_OP사용자 인터페이스에 대한 인터페이스를 정의하는 매크로 호출을 추가 하십시오.<br>~tensorflow/core/user_ops 에 파일을 만들었습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#include &quot;tensorflow/core/framework/op.h&quot;</div><div class="line">#include &quot;tensorflow/core/framework/shape_inference.h&quot;</div><div class="line"></div><div class="line">using namespace tensorflow;</div><div class="line"></div><div class="line">REGISTER_OP(&quot;ZeroOut&quot;)</div><div class="line">    .Input(&quot;to_zero: int32&quot;)</div><div class="line">    .Output(&quot;zeroed: int32&quot;)</div><div class="line">    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) &#123;</div><div class="line">      c-&gt;set_output(0, c-&gt;input(0));</div><div class="line">      return Status::OK();</div><div class="line">    &#125;);</div></pre></td></tr></table></figure></p>
<p>이 ZeroOut연산은 하나의 텐서 to_zero32 비트 정수를 입력으로 취해서 텐서 32 비트 정수 zeroed을 출력합니다.<br>op는 출력 텐서가 입력 텐서와 동일한 모양인지 확인하기 위해 shape 함수를 사용합니다.<br>예를 들어, 입력이 텐서 형태 [10, 20]이면이 모양 함수는 출력 모양도 [10, 20]으로 지정합니다.</p>
<ul>
<li>이름 지정에 대한 참고 사항 : op 이름은 CamelCase여야하며 binary file에 등록된 다른 모든 운영 체제 중에서 고유해야합니다.</li>
</ul>
<h1 id="op의-kernel코드-작성"><a href="#op의-kernel코드-작성" class="headerlink" title="op의 kernel코드 작성"></a>op의 kernel코드 작성</h1><p>인터페이스를 정의한 후에 op의 하나 이상의 구현을 제공하십시오.<br>커널을 만드려면 OpKernel을 확장하는 클래스를 만들어야합니다.<br>그리고 Compute method를 오버라이드 해야합니다.<br>Compute메서드는 OpKernelContext* type의 context 인수를 하나 제공합니다.<br>이 인수를 사용하여 입력 및 출력 텐서와 같은 유용한 항목에 액세스 할 수 있습니다.<br>위에 작성한 파일에 커널을 추가하십시오. 커널은 다음과 같이 생겼습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">#include &quot;tensorflow/core/framework/op_kernel.h&quot;</div><div class="line"></div><div class="line">using namespace tensorflow;</div><div class="line"></div><div class="line">class ZeroOutOp : public OpKernel &#123;</div><div class="line"> public:</div><div class="line">  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) &#123;&#125;</div><div class="line"></div><div class="line">  void Compute(OpKernelContext* context) override &#123;</div><div class="line">    // Grab the input tensor</div><div class="line">    const Tensor&amp; input_tensor = context-&gt;input(0);</div><div class="line">    auto input = input_tensor.flat&lt;int32&gt;();</div><div class="line"></div><div class="line">    // Create an output tensor</div><div class="line">    Tensor* output_tensor = NULL;</div><div class="line">    OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(),</div><div class="line">                                                     &amp;output_tensor));</div><div class="line">    auto output = output_tensor-&gt;flat&lt;int32&gt;();</div><div class="line"></div><div class="line">    // Set all but the first element of the output tensor to 0.</div><div class="line">    const int N = input.size();</div><div class="line">    for (int i = 1; i &lt; N; i++) &#123;</div><div class="line">      output(i) = 0;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    // Preserve the first input value if possible.</div><div class="line">    if (N &gt; 0) output(0) = input(0);</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>커널을 구현 한 후에는 TensorFlow 시스템에 등록하십시오.<br>등록시 이 커널이 실행될 다른 제약 조건을 지정합니다.<br>예를 들어, CPU 용으로 만든 커널 하나와 GPU 용으로 만든 커널을 따로 가질 수 있습니다.</p>
<p>그리고 이것을 ZeroOut op가 하기 위해서 아래의 코드를 zero_out.cc 코드에 추가합니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">REGISTER_KERNEL_BUILDER(Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU), ZeroOutOp);</div></pre></td></tr></table></figure></p>
<h1 id="op라이브러리-빌드"><a href="#op라이브러리-빌드" class="headerlink" title="op라이브러리 빌드"></a>op라이브러리 빌드</h1><p>두가지 방법을 제시하고 있습니다.<br>g++을 통한 방법과 bazel을 통한 방법인데요.<br>bazel을 통한 빌드가 더 빠르다는 커뮤니티원의 정보를 듣고 bazel만으로 빌드를 진행했습니다.</p>
<p>TensorFlow 소스가 설치되어있는 경우 TensorFlow의 빌드 시스템을 사용하여 작업을 컴파일 할 수 있습니다.<br>디렉토리에 다음 Bazel 빌드 규칙이있는 BUILD 파일을 tensorflow/core/user_ops놓습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">load(&quot;//tensorflow:tensorflow.bzl&quot;, &quot;tf_custom_op_library&quot;)</div><div class="line"></div><div class="line">tf_custom_op_library(</div><div class="line">    name = &quot;zero_out.so&quot;,</div><div class="line">    srcs = [&quot;zero_out.cc&quot;],</div><div class="line">)</div></pre></td></tr></table></figure></p>
<p>zero_out.so를 빌드하기 위해서는 아래의 명령어를 입력해주세요.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bazel build --config opt //tensorflow/core/user_ops:zero_out.so</div></pre></td></tr></table></figure></p>
<p>참고 : .so표준 cc_library규칙 을 사용하여 공유 라이브러리(파일)를 만들 수 있지만 tf_custom_op_library매크로를 사용하는 것이 좋습니다. 몇 가지 필수 종속성을 추가하고 공유 라이브러리가 TensorFlow의 플러그인로드 메커니즘과 호환되는지 확인하기위한 검사를 수행합니다.</p>
<h1 id="파이썬에서-op를-사용하기-위한-방법"><a href="#파이썬에서-op를-사용하기-위한-방법" class="headerlink" title="파이썬에서 op를 사용하기 위한 방법"></a>파이썬에서 op를 사용하기 위한 방법</h1><p>TensorFlow Python API는 tf.load_op_library동적 라이브러리를로드하고 op를 TensorFlow 프레임 워크에 등록하는 기능을 제공합니다.<br>load_op_libraryop와 커널을 위한 파이썬 래퍼를 포함하는 파이썬 모듈을 리턴합니다.<br>따라서 일단 op를 빌드하면 다음을 수행하여 Python에서 실행할 수 있습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line">zero_out_module = tf.load_op_library(&apos;zero_out.so&apos;)</div><div class="line">with tf.Session(&apos;&apos;):</div><div class="line">  zero_out_module.zero_out([[1, 2], [3, 4]]).eval()</div><div class="line"></div><div class="line"># Prints</div><div class="line">array([[1, 0], [0, 0]], dtype=int32)</div></pre></td></tr></table></figure></p>
<p>참고로 snake_name case가 되기 때문에 op의 이름이 C++에서 ZeroOut이었다면, 파이썬에서는 zero_out이 됩니다.</p>
<h1 id="테스트"><a href="#테스트" class="headerlink" title="테스트"></a>테스트</h1><p>성공적으로 op를 구현했는지 확인하는 좋은 방법은 테스트를 작성하는 것입니다.<br>다음 내용으로 zero_out_op_test.py 파일 을 만듭니다 .<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">class ZeroOutTest(tf.test.TestCase):</div><div class="line">  def testZeroOut(self):</div><div class="line">    zero_out_module = tf.load_op_library(&apos;zero_out.so&apos;)</div><div class="line">    with self.test_session():</div><div class="line">      result = zero_out_module.zero_out([5, 4, 3, 2, 1])</div><div class="line">      self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])</div><div class="line"></div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line">  tf.test.main()</div></pre></td></tr></table></figure></p>
<p>그런 다음 테스트를 실행하십시오 (tensorflow가 설치되어 있다고 가정).<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python zero_out_op_test.py</div></pre></td></tr></table></figure></p>
<h1 id="그런데-이대로-되시나요"><a href="#그런데-이대로-되시나요" class="headerlink" title="그런데 이대로 되시나요??"></a>그런데 이대로 되시나요??</h1><p>지금 op customizing 부분에 심각한 오류가 있는 것 같습니다.<br>bazel을 이용해서 op customizing을 하는 부분은 현재 오류가 있어서 안되는 것 같더군요.<br>그래서 g++로 다시 빌드를 해보았습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># 홈디렉토리에서</div><div class="line">TF_INC=$(python -c &apos;import tensorflow as tf; print(tf.sysconfig.get_include())&apos;)</div><div class="line"># tensorflow/tensorflow/core/uer_ops 경로에서</div><div class="line">g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC -I $TF_INC -O2</div></pre></td></tr></table></figure></p>
<p>자, 이렇게 빌드를 했더니 zero_out.so 파일이 해당 경로에 생겼습니다.<br>다시 파일로 돌아갔습니다.<br>그리고 path를 잘 못알아들어서 수동으로 다시 코드를 짜주었습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">import os.path</div><div class="line">import tensorflow as tf</div><div class="line">zero_out_module = tf.load_op_library(&apos;zero_out.so가 있는 경로 전부 루트부터 입력&apos;)</div><div class="line">sess = tf.Session()</div><div class="line">print (sess.run(zero_out_module.zero_out([[1,2], [3,4]])))</div></pre></td></tr></table></figure></p>
<p>자, 이제 정상 작동을 합니다.</p>
<p>이것으로 user customizing op를 텐서플로우에 추가하는 방법에 대한 설명을 마치겠습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;텐서플로우를 이용해서 소스코드를 작성하다보면 가끔 내가 만든 연산을 추가하고 싶다는 생각이 듭니다.&lt;br&gt;이럴 경우에 텐서플로우에서는 operation을 추가하는 방법을 공식홈페이지에서 설명해주고 있습니다.&lt;br&gt;&lt;a href=&quot;https://w
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="Internal" scheme="https://deeptensorflow.github.io/categories/Tensorflow/Internal/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="internal" scheme="https://deeptensorflow.github.io/tags/internal/"/>
    
      <category term="build" scheme="https://deeptensorflow.github.io/tags/build/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 내부 구조에 대해 알아보자</title>
    <link href="https://deeptensorflow.github.io/2017/02/21/tensorflow-architecture-feature/"/>
    <id>https://deeptensorflow.github.io/2017/02/21/tensorflow-architecture-feature/</id>
    <published>2017-02-21T06:33:44.000Z</published>
    <updated>2017-02-21T12:24:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>본 내용은 <a href="https://www.tensorflow.org/extend/architecture" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/extend/architecture</a> 공홈의 내용을 번역한 것입니다.</p>
<h1 id="텐서플로우의-내부는-어떻게-생겼을까"><a href="#텐서플로우의-내부는-어떻게-생겼을까" class="headerlink" title="텐서플로우의 내부는 어떻게 생겼을까?"></a>텐서플로우의 내부는 어떻게 생겼을까?</h1><p><img src="https://deeptensorflow.github.io/images/tensorflowarchitecture.png" alt="tensorflowarchitecture"><br>요런식으로 생겼습니다.<br>주목해야할 점들은 다음과 같습니다.</p>
<ul>
<li>클라이언트(tensorflow로 코드를 작성하는 부분)</li>
<li>계산을 data flow graph으로 정의</li>
<li>세션을 사용하여 그래프 실행</li>
<li>Distributed Master</li>
<li>Session.run ()의 인수로 사용된 특정부분의 그래프를 정리</li>
<li>하위 그래프를 다른 프로세스와 장치에서 실행되는 여러 조각으로 분할</li>
<li>그래프 조각을 worker에 뿌림</li>
<li>worker service</li>
<li>사용 가능한 하드웨어 (CPU, GPU 등)에 적합한 커널 구현을 사용하여 그래프 작업 스케줄링 가능</li>
<li>다른 작업자 서비스와 작업 결과를 송수신</li>
<li>커널 구현</li>
<li>개별 그래프에 대한 연산 수행</li>
</ul>
<h1 id="대략적인-워크-플로우-그래프"><a href="#대략적인-워크-플로우-그래프" class="headerlink" title="대략적인 워크 플로우 그래프"></a>대략적인 워크 플로우 그래프</h1><p><img src="https://deeptensorflow.github.io/images/tensorflow_worker.png" alt="텐서플로우워커"><br>저 위의 그림에서 MASTER는 분산 프로그래밍된 TensorFlow에만 존재합니다.<br>Tensorflow가 단일버전으로 이루어져있다면 마스터가하는 모든 작업을 수행하지만 로컬 프로세스의 장치와만 통신하는 특수 세션 구현이 포함됩니다.</p>
<h1 id="클라이언트에서-일어나는-일"><a href="#클라이언트에서-일어나는-일" class="headerlink" title="클라이언트에서 일어나는 일"></a>클라이언트에서 일어나는 일</h1><p>사용자는 계산 그래프를 작성하는 클라이언트 TensorFlow 프로그램을 작성합니다.<br>여러 라이브러리들을 써서 작업할수도 있으며 여러 layer들을 구성해 가며 추상화 작업을 진행합니다.<br>TensorFlow는 Python과 C++언어를 지원합니다.</p>
<h1 id="Distributed-master에서-일어나는-일"><a href="#Distributed-master에서-일어나는-일" class="headerlink" title="Distributed master에서 일어나는 일"></a>Distributed master에서 일어나는 일</h1><p>그래프를 분할하는 작업을 합니다.<br>이렇게 분할된 그래프에 분산 노드간에 정보를 전달하기 위해 송수신 노드를 삽입합니다<br><img src="https://deeptensorflow.github.io/images/psandworker" alt="psandworker"><br>그리고는 task에게 일을 전달하는 것입니다.<br>이런식으로 텐서플로우에서는 코드를 병렬적으로 빠르게 수행할 수가 있습니다.</p>
<h1 id="Worker가-하는-일"><a href="#Worker가-하는-일" class="headerlink" title="Worker가 하는 일"></a>Worker가 하는 일</h1><ul>
<li>마스터로부터 온 일을 처리함</li>
<li>연산에 대한 커널의 실행들을 스케줄링함</li>
<li>작업간의 직접적인 통신 역할(한쪽이 죽으면 그 일을 다른곳에 넘긴다던지..)<br>Worker는 커널을 로컬 장치에 디스패치하고 가능하면 다중 CPU 코어 또는 GPU 스트림을 사용하여 병렬로 커널을 실행합니다.</li>
</ul>
<p>즉 Worker는 장치 유형의 각 쌍에 대해 Send 및 Recv 작업을 전문적으로 수행합니다.<br>1) CPU와 CPU 끼리는 cudaMemcpyAsync() API를 사용하여 계산 및 데이터 전송을 중첩합니다.<br>2) CPU와 GPU 끼리는 값 비싼 복사를 피하기 위해 peer to peer DMA를 사용합니다.</p>
<p>작업간 전송의 경우 tensorflow는 다음의 프로토콜을 사용합니다.<br>1) TCP를 통한 gRPC<br>2) 수렴형 이더넷을 통한 RDMA</p>
<p>또한 다중 GPU 통신을위한 NVIDIA의 NCCL 라이브러리에 대한 예비 지원을 받았습니다.</p>
<h1 id="커널-구현"><a href="#커널-구현" class="headerlink" title="커널 구현"></a>커널 구현</h1><p>런타임에는 수학, 배열 조작, 제어 흐름 및 상태 관리 작업을 포함하여 200 개가 넘는 표준 작업이 포함됩니다.<br>각 작업들은 각 device에 맞게 최적화시킬 수 있습니다.<br>많은 운영 커널은 Eigen :: Tensor를 사용하여 구현되며, C ++ 템플릿을 사용하여 멀티 코어 CPU 및 GPU를위한 효율적인 병렬 코드를 생성합니다.<br>그러나 우리는보다 효율적인 커널 구현이 가능한 cuDNN과 같은 라이브러리를 자유롭게 사용합니다.<br>우리는 또한 모바일 장치 및 고처리량 데이터센터 응용프로그램과 같은 환경에서 더 빠른 추론을 가능하게하는 quantization을 구현했으며 quantum 연산을 가속화하기 위해 gemmlowp low-precision matrix library 를 사용합니다.<br>하위 연산을 연산 조합으로 나타 내기가 어렵거나 비효율적 인 경우 사용자는 C ++로 작성된 효율적인 구현을 제공하는 추가 커널을 등록 할 수 있습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;본 내용은 &lt;a href=&quot;https://www.tensorflow.org/extend/architecture&quot; rel=&quot;external nofollow noopener noreferrer&quot; target=&quot;_blank&quot;&gt;https://www.te
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="Internal" scheme="https://deeptensorflow.github.io/categories/Tensorflow/Internal/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="internal" scheme="https://deeptensorflow.github.io/tags/internal/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 빌드하는 방법 (텐서플로우에 내코드 추가하기)</title>
    <link href="https://deeptensorflow.github.io/2017/02/21/how-to-build-tensorflow-with-pip/"/>
    <id>https://deeptensorflow.github.io/2017/02/21/how-to-build-tensorflow-with-pip/</id>
    <published>2017-02-21T00:47:00.000Z</published>
    <updated>2017-02-21T01:25:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="직접-bazel로-빌드했을때의-장점"><a href="#직접-bazel로-빌드했을때의-장점" class="headerlink" title="직접 bazel로 빌드했을때의 장점?"></a>직접 bazel로 빌드했을때의 장점?</h1><p>tensorflow 커뮤니티에 올라온 정보들에 따르면 직접 빌드했을때 속도가 소폭 향상된다고 합니다.<br>추후 직접 실험을 해서 속도비교를 해서 올릴 예정입니다.<br>그리고 자신이 직접 내부의 소스코드를 수정해서 빌드하면 ‘나만의 텐서플로우’를 만들 수 있습니다.</p>
<h1 id="빌드-전-개발환경-세팅"><a href="#빌드-전-개발환경-세팅" class="headerlink" title="빌드 전 개발환경 세팅"></a>빌드 전 개발환경 세팅</h1><p>pip(파이썬 패키지 매니저)과 java-jdk가 설치되어 있어야 합니다.<br>설치 방법은 OS환경마다 다르지만 매우 간단합니다.<br>아마 대부분 설치가 이미 되어있을 것이라고 생각하기 때문에 그냥 넘어가겠습니다.</p>
<h1 id="bazel-다운로드"><a href="#bazel-다운로드" class="headerlink" title="bazel 다운로드"></a>bazel 다운로드</h1><p><a href="https://bazel.build/" rel="external nofollow noopener noreferrer" target="_blank">https://bazel.build/</a> 에서 다운로드가 가능합니다.<br>curl로 다운 받는 방법은 아래와 같습니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">export BAZELRC=/home/&lt;yourid&gt;/.bazelrc</div><div class="line">export BAZEL_VERSION=0.4.2</div><div class="line">mkdir /home/&lt;yourid&gt;/bazel</div><div class="line">cd /home/&lt;yourid&gt;/bazel</div><div class="line">curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div><div class="line">curl -fSsL -o /home/&lt;yourid&gt;/bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE.txt</div><div class="line">chmod +x bazel-*.sh</div><div class="line">sudo ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div><div class="line">cd /home/&lt;yourid&gt;/</div><div class="line">rm -f /home/&lt;yourid&gt;/bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div></pre></td></tr></table></figure></p>
<h1 id="tensorflow-github에서-다운로드"><a href="#tensorflow-github에서-다운로드" class="headerlink" title="tensorflow github에서 다운로드"></a>tensorflow github에서 다운로드</h1><p>소스가 있어야 빌드를 하겠죠?<br>그리고 wheel, six, numpy 패키지가 필요합니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/tensorflow/tensorflow</div><div class="line">cd tensorflow</div><div class="line">git checkout r1.0 #빌드를 원하는 버전을 입력하시면 되요.</div><div class="line">sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel #ubuntu 쓰는 분들만</div><div class="line">brew install python3 #맥 쓰는 분들만</div><div class="line">sudo pip3 install six numpy wheel #맥쓰는 분들만</div></pre></td></tr></table></figure></p>
<p>여기서 빌드를 하기 전에 소스코드를 고쳐서 텐서플로우에 내 소스를 추가할 수 있습니다.<br>공식 홈페이지에서 해당 내용도 있습니다.<br><a href="https://www.tensorflow.org/extend/adding_an_op" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/extend/adding_an_op</a><br>다음 포스팅으로 자세히 해당 내용에 대해서도 다루어 보겠습니다.</p>
<h1 id="tensorflow에서는-설정을-쉽게-하는-방법을-제공합니다"><a href="#tensorflow에서는-설정을-쉽게-하는-방법을-제공합니다" class="headerlink" title="tensorflow에서는 설정을 쉽게 하는 방법을 제공합니다."></a>tensorflow에서는 설정을 쉽게 하는 방법을 제공합니다.</h1><p>tensorflow 폴더에서 ./configure 하시면 빌드 설정을 쉽게 하도록 도와줍니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">$ cd tensorflow  # cd to the top-level directory created</div><div class="line">$ ./configure</div><div class="line">Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7</div><div class="line">Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native]:</div><div class="line">Do you wish to use jemalloc as the malloc implementation? [Y/n]</div><div class="line">jemalloc enabled</div><div class="line">Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]</div><div class="line">No Google Cloud Platform support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with Hadoop File System support? [y/N]</div><div class="line">No Hadoop File System support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]</div><div class="line">No XLA JIT support will be enabled for TensorFlow</div><div class="line">Found possible Python library paths:</div><div class="line">  /usr/local/lib/python2.7/dist-packages</div><div class="line">  /usr/lib/python2.7/dist-packages</div><div class="line">Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]</div><div class="line">Using python library path: /usr/local/lib/python2.7/dist-packages</div><div class="line">Do you wish to build TensorFlow with OpenCL support? [y/N] N</div><div class="line">No OpenCL support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with CUDA support? [y/N] Y</div><div class="line">CUDA support will be enabled for TensorFlow</div><div class="line">Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:</div><div class="line">Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0</div><div class="line">Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:</div><div class="line">Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5</div><div class="line">Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:</div><div class="line">Please specify a list of comma-separated Cuda compute capabilities you want to build with.</div><div class="line">You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.</div><div class="line">Please note that each additional compute capability significantly increases your build time and binary size.</div><div class="line">[Default is: &quot;3.5,5.2&quot;]: 3.0</div><div class="line">Setting up Cuda include</div><div class="line">Setting up Cuda lib</div><div class="line">Setting up Cuda bin</div><div class="line">Setting up Cuda nvvm</div><div class="line">Setting up CUPTI include</div><div class="line">Setting up CUPTI lib64</div><div class="line">Configuration finished</div></pre></td></tr></table></figure></p>
<p>중간에 파이썬 버전 선택이나 CUDA 지원 여부 자신의 환경에 맞게 잘 세팅해주세요.<br>제안들이 친절하게 분류되어있어서 어려움은 없을 것 같습니다.</p>
<h1 id="bazel로-빌드하기"><a href="#bazel로-빌드하기" class="headerlink" title="bazel로 빌드하기"></a>bazel로 빌드하기</h1><p>설정이 끝났다면 빌드를 해야겠죠?<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package #cpu버전일경우</div><div class="line">bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package  #gpu버전일 경우</div></pre></td></tr></table></figure></p>
<p>pip 패키지로 관리하기 쉽게 만들어줍시다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg</div></pre></td></tr></table></figure></p>
<p>pip으로 다운받아줍시다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo pip install /tmp/tensorflow_pkg/tensorflow-1.0.0-py2-none-any.whl #python2버전</div><div class="line">sudo pip3 install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp36-cp36m-macosx_10_12_x86_64.whl #python3버전</div></pre></td></tr></table></figure></p>
<p>이건 설정에 따라서 다르닌깐요<br>sudo pip(파이썬3이면 pip3) install /tmp/tensorflow_pkg/ 한다음에 tab키 쳐주시면 뜨는데 그리고 엔터 눌러주세요.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;직접-bazel로-빌드했을때의-장점&quot;&gt;&lt;a href=&quot;#직접-bazel로-빌드했을때의-장점&quot; class=&quot;headerlink&quot; title=&quot;직접 bazel로 빌드했을때의 장점?&quot;&gt;&lt;/a&gt;직접 bazel로 빌드했을때의 장점?&lt;/h1&gt;&lt;p&gt;
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="Internal" scheme="https://deeptensorflow.github.io/categories/Tensorflow/Internal/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="internal" scheme="https://deeptensorflow.github.io/tags/internal/"/>
    
      <category term="build" scheme="https://deeptensorflow.github.io/tags/build/"/>
    
  </entry>
  
  <entry>
    <title>시그모이드 함수는 왜 쓰일까? logistic regression, softmax regression</title>
    <link href="https://deeptensorflow.github.io/2017/02/19/why-use-sigmoid-and-what-is-logistic-classification/"/>
    <id>https://deeptensorflow.github.io/2017/02/19/why-use-sigmoid-and-what-is-logistic-classification/</id>
    <published>2017-02-19T09:08:56.000Z</published>
    <updated>2017-02-19T11:38:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="시그모이드-함수란"><a href="#시그모이드-함수란" class="headerlink" title="시그모이드 함수란?"></a>시그모이드 함수란?</h1><p><img src="https://deeptensorflow.github.io/images/sigmoid.png" alt="sigmoid"><br>그림 실력 지못미 ㅠㅠ<br>위의 그림처럼 생긴 함수입니다.<br>0과 1 사이에서 값이 정해진다는 것만 유심히 보시면 됩니다.<br>linear regression을 지난번 포스팅에서 y = W * X + b의 꼴로 설명드렸지요?<br>(<a href="https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/">https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/</a>)<br>이러한 꼴로는 해석하기 힘든 현상들이 있어서 나온 것이 바로 logistic regression이고 여기서 쓰이는 함수가 sigmoid 함수입니다.</p>
<h1 id="logistic-regression이-나오게-된-계기를-먼저-알자"><a href="#logistic-regression이-나오게-된-계기를-먼저-알자" class="headerlink" title="logistic regression이 나오게 된 계기를 먼저 알자"></a>logistic regression이 나오게 된 계기를 먼저 알자</h1><p>이전 포스팅에서 다룬 linear regression을 적용하기 힘든 부분은 바로 true of flase 꼴을 처리할 때입니다.<br>왜 처리하기가 힘드냐? 기본적으로 y = a<em>x + b 꼴의 선형 함수는 우선 x에 따른 대응되는 y값이 무한대입니다.<br>0과 1로 처리를 하고싶은 logistic classification의 경우 적용하기 무리가 있지요.<br>0 아니면 1, true 아니면 flase, 모 아니면 도 이런 경우이지요.<br>현실의 예를 들자면 스팸메일인지 아닌지, 합격인지 불합격인지가 이런 경우에 해당됩니다.<br>그래서 이를 대체할 함수를 찾다가! 딱! 시그모이드 함수를 발견하게 된 것입니다.<br>그리고 시그모이드 함수를 기존의 linear regression에 그대로 씌워봤는데 효과가 좋아서 이것을 logistic regression이라고 하게 된 것이지요.<br>기본적으로 0과 1사이에서 값이 노는데다가 0.5 기준점으로 원점대칭 꼴이라서 코드 적용도 쉽습니다.<br>기존의 linear regression a</em>x+b의 부분을 시그모이드 함수의 x부분에 넣어주었더니 실제로 양자택일의 경우에 굉장히 뛰어난 효율을 보여줬습니다.(1/(1+e^(-(ax+b))))<br>현재도 정말 유용하게 쓰이고 있는 함수 모델입니다.</p>
<h1 id="그냥-바로-코드에-적용시켜도-되나요"><a href="#그냥-바로-코드에-적용시켜도-되나요" class="headerlink" title="그냥 바로 코드에 적용시켜도 되나요?"></a>그냥 바로 코드에 적용시켜도 되나요?</h1><p>sigmoid 를 이용한 logistic classification 코드를 작성하는 방법을 설명해주는 강의가 있습니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/6vzchGYEJBc" frameborder="0" allowfullscreen></iframe></div><br>요약하자면 cost함수를 구성할때 그대로 적용하면 굴곡진 부분들이 많아져서 gradient descent 알고리즘 적용에는 무리가 있으니 log함수를 취해줘서 그래프를 펴주자… 이런 내용입니다.<br>꼭 한번 강의를 듣는 것을 추천드립니다.<br>홍콩 과기대의 김성훈 교수님의 강의입니다.</p>
<h1 id="softmax-regression-이라는-것도-있던데…"><a href="#softmax-regression-이라는-것도-있던데…" class="headerlink" title="softmax regression 이라는 것도 있던데…"></a>softmax regression 이라는 것도 있던데…</h1><p>이것은 그냥 logistic regression을 muti-variable 형식으로 구성한 것이라고 보면 됩니다.<br>예를 들어 표현해 보도록 하겠습니다.<br>기존의 logistic regression은 양자택일을 해주었죠?<br>그리고 그것을 돕는 함수가 sigmoid 함수였습니다.<br>이것을 한번 응용해 보도록 하겠습니다.<br>A학점 B학점 C학점이 있다고 가정하겠습니다.<br>공부하는 시간에 따른 학점이 얼마나 나오는지 알아보고 싶습니다.<br>공부하는 시간을 X라고 두면 이에 따른 weight와 bias가 있을 것입니다.<br>대충 Y = W * X + b 꼴이 될 것입니다.<br>여기에 우리가 배운 logistic regression을 적용하면 시그모이드가 씌워져서 0~1사이의 값이 나오겠죠?<br>이게 A학점, B학점, C학점에 대해 각각 따로따로 있는 것입니다.<br><img src="https://deeptensorflow.github.io/images/softmax.png" alt="softmax"><br>각 학점에 대한 bias와 weight를 둡니다.<br>그리고 이것을 sigmoid를 씌워서 0~1사이의 값으로 나오게 하고 각 값들의 합을 1로 하여 확률로 변환하는 과정 까지를 softmax regression이라고 합니다.<br>그리고 cost함수를 짜겠죠?(log함수를 이용합니다. 위의 유투브 영상에 짜는 방법 나옴!)<br>실제 값을 출력할 때에는 argmax를 이용해서 가장 확률이 높은 값을 뽑습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;시그모이드-함수란&quot;&gt;&lt;a href=&quot;#시그모이드-함수란&quot; class=&quot;headerlink&quot; title=&quot;시그모이드 함수란?&quot;&gt;&lt;/a&gt;시그모이드 함수란?&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://deeptensorflow.github.
    
    </summary>
    
      <category term="Machinelearning" scheme="https://deeptensorflow.github.io/categories/Machinelearning/"/>
    
      <category term="News" scheme="https://deeptensorflow.github.io/categories/Machinelearning/News/"/>
    
    
      <category term="machinelearning" scheme="https://deeptensorflow.github.io/tags/machinelearning/"/>
    
      <category term="algorithm" scheme="https://deeptensorflow.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>선형회귀란 무엇을까? 텐서플로우를 통해 알아보자(linear regression)</title>
    <link href="https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/"/>
    <id>https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/</id>
    <published>2017-02-19T04:44:28.000Z</published>
    <updated>2017-02-19T06:22:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="선형회귀-linear-regression"><a href="#선형회귀-linear-regression" class="headerlink" title="선형회귀(linear regression)"></a>선형회귀(linear regression)</h1><ul>
<li>위키백과</li>
</ul>
<p>선형회귀란  종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법입니다.<br>한 개의 설명 변수에 기반한 경우에는 단순 선형 회귀, 둘 이상의 설명 변수에 기반한 경우에는 다중 선형 회귀라고 합니다.</p>
<ul>
<li>쉽게 설명하자면…</li>
</ul>
<p>어떤사람은 2시간 공부해서 시험점수를 30점을 받았습니다.<br>어떤사람은 3시간 공부해서 40점을, 어떤사람은 4시간 공부해서 50점을 받았습니다.<br>이럴 경우에 공부시간과 시험점수 사이에 어떤 관계가 있는지 알아보고 싶겠죠?<br>이럴 때 자주 쓰이는 기법이 선형 회귀입니다.<br>그리고 더 세분화 하자면 결과에 미치는 요인이 한개이기 때문에 단순 선형 회귀라고 부릅니다.<br>단순한 공부시간 뿐만 아니라 학교의 출석율도 한번 설명 변수로 넣어보겠습니다.<br>어떤 사람은 2시간을 공부하고 학교에 5번 출석을 해서 20점을 받았습니다.<br>어떤 사람은 2시간을 공부하고 학교에 10번을 출석해서 30점을 받았구요!<br>어떤 사람은 5시간을 공부하고 학교에 20번을 출석해서 50점을 받았다고 가정하겠습니다.<br>공부시간, 학교 출석율이 시험점수에 얼마나 영향을 미치는지 궁금하죠?<br>이럴때 자주 쓰이는 기법이 선형 회귀입니다.<br>더 세분화 하자면 설명 변수가 둘 이상이니 다중 선형 회귀라고 합니다.</p>
<ul>
<li>방정식으로 알아보자</li>
</ul>
<p>위의 경우에 아래의 방정식이 세워지죠?<br>Y(시험점수) = x1(공부한시간) <em> w1(공부시간과 시험점수의 상관계수) + x2(학교 출석율) </em> w2(학교 출석율과 시험점수의 상관계수) + b(보정값)<br>요약하자면 Y = x1<em>w1 +x2</em>w2 + b 입니다.<br>중학교 때 많이 본 함수이지요?<br>이런 모델을 써서 설명변수(x1, x2)와 종속변수(Y)의 상관관계를 알고자 하는 방법인 것입니다.</p>
<ul>
<li>텐서플로우로 단순 선형 회귀에 대해 알아보자</li>
</ul>
<p>일부러 상관관계를 알기 쉽도록 눈에 보이는 모델을 써봤습니다.<br>공부시간이 1, 2, 3시간일때 시험 점수가 2, 4, 6점이라면?<br>Y = x1*w1 + b의 모델이 짜질 것입니다.<br>그리고 w1은 2, b는 0이 되어야 주어진 방정식을 만족할 것이라는 것을 우리는 알 수 있죠.<br>한번 텐서플로우 코드로 확인해 보겠습니다.</p>
<figure class="highlight plain"><figcaption><span>tf_linear_regression</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"># 텐서플로우를 사용할 것을 알려줍니다.</div><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line"># x_data는 공부시간, y_data는 시험성적 입니다.</div><div class="line">x_data = [1, 2, 3]</div><div class="line">y_data = [2, 4, 6]</div><div class="line"></div><div class="line"># W는 설명변수, b는 보정값 입니다.</div><div class="line">W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))</div><div class="line">b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))</div><div class="line"></div><div class="line"># placeholder를 사용하면 변수의 형태만 지정해주고 나중에 값을 넣어줘도 됩니다.</div><div class="line">X = tf.placeholder(tf.float32)</div><div class="line">Y = tf.placeholder(tf.float32)</div><div class="line"></div><div class="line"># 방정식 모델입니다.</div><div class="line">hypothesis = W * X + b</div><div class="line"></div><div class="line"># cost 함수입니다. 뒤어서 설명하겠습니다.</div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - Y))</div><div class="line"></div><div class="line"># Gradient Descent 또한 뒤에서 설명하겠습니다.</div><div class="line">a = tf.Variable(0.1)</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)</div><div class="line"></div><div class="line"># 변수들을 초기화합니다.</div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line"># 텐서플로우를 시작하게 하는 구문이라고 보시면 됩니다. 세션을 지정해줍니다.</div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line"># X에 x_data를, Y에 y_data를 넣어서 2001번 소스를 돌려가며 W와 b값을 찾아갑니다.</div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print(step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W), sess.run(b))</div><div class="line"></div><div class="line"># 5시간 공부했을때와 2.5시간 공부했을 때 몇점이 나올지 출력해봅니다.</div><div class="line">print(sess.run(hypothesis, feed_dict=&#123;X: 5&#125;))</div><div class="line">print(sess.run(hypothesis, feed_dict=&#123;X: 2.5&#125;))</div><div class="line"></div></pre></td></tr></table></figure>
<ul>
<li>결과입니다.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># 순서대로 몇번째 트레이닝인지, 오차범위, W값, b값 입니다.</div><div class="line">0 0.245183 [ 2.28380156] [-0.13001066]</div><div class="line">200 3.87879e-07 [ 2.00072336] [-0.00164423]</div><div class="line">400 2.25526e-11 [ 2.00000548] [ -1.27652002e-05]</div><div class="line">600 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">800 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">1000 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">1200 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">1400 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">1600 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">1800 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line">2000 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]</div><div class="line"></div><div class="line"># 5시간 공부했을 때와 2.5시간 공부했을 때를 출력해줍니다.</div><div class="line">[ 10.00000286]</div><div class="line">[ 5.00000048]</div></pre></td></tr></table></figure>
<ul>
<li>cost 함수 &amp; gradient descent란?</li>
</ul>
<p>김성훈 교수님의 강의가 이것을 이해하는데는 최고 같습니다.<br>아래의 비디오 두편만 보면 이해가 빡!<br><div class="video-container"><iframe src="//www.youtube.com/embed/Hax03rCn3UI" frameborder="0" allowfullscreen></iframe></div><br><div class="video-container"><iframe src="//www.youtube.com/embed/TxIVr-nk1so" frameborder="0" allowfullscreen></iframe></div></p>
<ul>
<li>다중 선형 회귀 함수는 어떻게 처리를 할까요?</li>
</ul>
<p>다중 선형 회귀함수를 보기 좋게 처리하려면 한가지 아이디어가 필요합니다.<br>행렬의 아이디어가 필요한데요.<br>Y = X1<em>W1 + X2</em>W2 + X3<em>W3 + …. + b 이런 꼴이 선형 회귀 모델인데요.<br>이것을 어떻게 간결하게 표현할 방법이 없을까요?<br>있습니다!<br>Y = X1</em>W1 + X2<em>W2 + X3</em>W3 +… + 1*b의 꼴로 두면 됩니다.<br>그리고 이것을 행렬로 변환!<br><img src="https://deeptensorflow.github.io/images/linear_regression.png" alt="linearregression"><br>요런식으로 행렬로 관리하면 되겠죠?<br>(아, b1, b2, … bn은 전부 같은 값입니다.)<br>그런데 더 간략하게 하고 싶다면 b까지 행렬에 포함시킬 수 있습니다.<br><img src="https://deeptensorflow.github.io/images/multi_linear_regression.png" alt="multi_linearregression"><br>이럴경우에 코드는 어떻게 되냐구요?</p>
<ul>
<li>다중 선형 회귀 함수 텐서플로우 예시 코드</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">import tensorflow as tf</div><div class="line"></div><div class="line">x_data = [[1., 2., 5.],[1., 3., 7.], [1., 4., 10.], [1., 7., 12.]]</div><div class="line">y_data = [1., 2., 3., 4.]</div><div class="line"></div><div class="line">W = tf.Variable(tf.random_uniform([3,1], -1, 1))</div><div class="line"></div><div class="line"># 이거 한줄로 가설함수 끝!</div><div class="line">hypothesis = tf.matmul(x_data, W)</div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(hypothesis - y_data))</div><div class="line"></div><div class="line">a = tf.Variable(0.01)  # learning rate, alpha</div><div class="line">optimizer = tf.train.GradientDescentOptimizer(a)</div><div class="line">train = optimizer.minimize(cost)  # goal is minimize cost</div><div class="line"></div><div class="line">init = tf.global_variables_initializer()</div><div class="line"></div><div class="line">sess = tf.Session()</div><div class="line">sess.run(init)</div><div class="line"></div><div class="line">for step in range(2001):</div><div class="line">    sess.run(train)</div><div class="line">    if step % 200 == 0:</div><div class="line">        print (step, sess.run(cost), sess.run(W))</div></pre></td></tr></table></figure>
<p>다중 선형 회귀를 이용했는데도(W 2개 b 1개) hypothesis 함수 코드가 엄청 간결하죠?<br>행렬의 위력입니다~ (다들 선형대수 열공을..)<br>참고로 x_data와 y_data에는 별다른 의미 없는 값을 넣었습니다.<br>그냥 소스코드 참고용이라… ㅎ</p>
<h1 id="결론은"><a href="#결론은" class="headerlink" title="결론은?"></a>결론은?</h1><p>linear regression이 대략적으로 어떤 요인에 미치는 변수들의 패턴을 선형적으로 파악하고자 하는 것이고 tensorflow를 이용하면 쉽게 구현이 가능하다!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;선형회귀-linear-regression&quot;&gt;&lt;a href=&quot;#선형회귀-linear-regression&quot; class=&quot;headerlink&quot; title=&quot;선형회귀(linear regression)&quot;&gt;&lt;/a&gt;선형회귀(linear regress
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="App" scheme="https://deeptensorflow.github.io/categories/Tensorflow/App/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="linearregression" scheme="https://deeptensorflow.github.io/tags/linearregression/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우1.0 설치시 일어나는 기본 오류를 잡아보자 (bazel로 소스코드 빌드)</title>
    <link href="https://deeptensorflow.github.io/2017/02/19/how-to-handle-tensorflow1-error/"/>
    <id>https://deeptensorflow.github.io/2017/02/19/how-to-handle-tensorflow1-error/</id>
    <published>2017-02-19T03:23:03.000Z</published>
    <updated>2017-02-21T00:02:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우-1-0을-pip으로-설치하고-사용하면-일어나는-오류"><a href="#텐서플로우-1-0을-pip으로-설치하고-사용하면-일어나는-오류" class="headerlink" title="텐서플로우 1.0을 pip으로 설치하고 사용하면 일어나는 오류"></a>텐서플로우 1.0을 pip으로 설치하고 사용하면 일어나는 오류</h1><p>tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.<br>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.<br>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.<br>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.<br>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.</p>
<p>이런 오류를 보신적이 없으신가요?<br>텐서플로우1.0을 pip(pip3)으로 설치하면 생기는 오류입니다.<br>간단한 방법으로 (하지만 시간이 조금 걸리는 방법) 해결할 수 있습니다.</p>
<h1 id="bazel을-설치하자"><a href="#bazel을-설치하자" class="headerlink" title="bazel을 설치하자"></a>bazel을 설치하자</h1><p>bazel은 구글에서 만든 빌드 툴입니다.<br><a href="https://bazel.build/" rel="external nofollow noopener noreferrer" target="_blank">https://bazel.build/</a> 에서 다운로드가 가능합니다.<br>apt-get이나 homebrew 를 통해서도 설치가 가능하구요~<br>자 설치가 끝났으면 텐서플로우 소스코드를 직접 빌드해보겠습니다.</p>
<p>예)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">export BAZELRC=/home/&lt;yourid&gt;/.bazelrc</div><div class="line">export BAZEL_VERSION=0.4.2</div><div class="line"></div><div class="line">mkdir /home/&lt;yourid&gt;/bazel</div><div class="line">cd /home/&lt;yourid&gt;/bazel</div><div class="line">curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div><div class="line">curl -fSsL -o /home/&lt;yourid&gt;/bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE.txt</div><div class="line">chmod +x bazel-*.sh</div><div class="line">sudo ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div><div class="line">cd /home/&lt;yourid&gt;/</div><div class="line">rm -f /home/&lt;yourid&gt;/bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh</div></pre></td></tr></table></figure>
<h1 id="텐서플로우-소스코드-빌드하는-방법"><a href="#텐서플로우-소스코드-빌드하는-방법" class="headerlink" title="텐서플로우 소스코드 빌드하는 방법"></a>텐서플로우 소스코드 빌드하는 방법</h1><ul>
<li>텐서플로우 소스코드를 깃허브에서 받은 다음에 python3, numpy,  wheel, six를 pip을 통해 받습니다.</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">git clone https://github.com/tensorflow/tensorflow</div><div class="line">cd tensorflow</div><div class="line">git checkout r1.0 #빌드를 원하는 버전을 입력하시면 되요.</div><div class="line">sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel #ubuntu 쓰는 분들만</div><div class="line">brew install python3 #맥 쓰는 분들만</div><div class="line">sudo pip3 install six numpy wheel #맥쓰는 분들만</div></pre></td></tr></table></figure>
<ul>
<li>GPU 쓰실 분들은 아래의 명령어도 터미널에서 입력해주세요.</li>
</ul>
<p>저는 PC에 GPU가 안달려있어서 테스트를 못해봤네요.<br>조만간 GPU를 달 계획입니다!<br>그런데 아마 오류는 없을거에요.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install libcupti-dev #ubuntu 쓰는 분들만</div><div class="line">brew install coreutils #맥쓰는 분들만</div><div class="line">sudo xcode-select -s /Application/Xcode-7.2/Xcode.app #맥쓰는 분들만</div></pre></td></tr></table></figure></p>
<ul>
<li>configure를 해봅시다.</li>
</ul>
<figure class="highlight plain"><figcaption><span>tensorflow.org code</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">$ cd tensorflow  # cd to the top-level directory created</div><div class="line">$ ./configure</div><div class="line">Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7</div><div class="line">Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native]:</div><div class="line">Do you wish to use jemalloc as the malloc implementation? [Y/n]</div><div class="line">jemalloc enabled</div><div class="line">Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]</div><div class="line">No Google Cloud Platform support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with Hadoop File System support? [y/N]</div><div class="line">No Hadoop File System support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]</div><div class="line">No XLA JIT support will be enabled for TensorFlow</div><div class="line">Found possible Python library paths:</div><div class="line">  /usr/local/lib/python2.7/dist-packages</div><div class="line">  /usr/lib/python2.7/dist-packages</div><div class="line">Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]</div><div class="line">Using python library path: /usr/local/lib/python2.7/dist-packages</div><div class="line">Do you wish to build TensorFlow with OpenCL support? [y/N] N</div><div class="line">No OpenCL support will be enabled for TensorFlow</div><div class="line">Do you wish to build TensorFlow with CUDA support? [y/N] Y</div><div class="line">CUDA support will be enabled for TensorFlow</div><div class="line">Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:</div><div class="line">Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0</div><div class="line">Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:</div><div class="line">Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5</div><div class="line">Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:</div><div class="line">Please specify a list of comma-separated Cuda compute capabilities you want to build with.</div><div class="line">You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.</div><div class="line">Please note that each additional compute capability significantly increases your build time and binary size.</div><div class="line">[Default is: &quot;3.5,5.2&quot;]: 3.0</div><div class="line">Setting up Cuda include</div><div class="line">Setting up Cuda lib</div><div class="line">Setting up Cuda bin</div><div class="line">Setting up Cuda nvvm</div><div class="line">Setting up CUPTI include</div><div class="line">Setting up CUPTI lib64</div><div class="line">Configuration finished</div></pre></td></tr></table></figure>
<p>특별히 신경써야할 부분은 처음에 나오는 이부분들입니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Please specify the location of python. [Default is /usr/bin/python]: (설정할 파이썬 path)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Do you wish to build TensorFlow with CUDA support? Y(gpu 쓰실 분들은 y해야겠죠~)</div></pre></td></tr></table></figure>
<p>잘 모르시겠으면 그냥 다 N 누르면서 진행하시면 원래 쓰시던 tensorflow 나올거에요~<br>영어 잘하시면 직접 해석하시면서 설정을 해주세요. ㅎㅎ</p>
<ul>
<li>bazel로 빌드하기</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package #cpu버전일경우</div><div class="line">bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package  #gpu버전일 경우</div></pre></td></tr></table></figure>
<ul>
<li>패키지화하기</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg</div></pre></td></tr></table></figure>
<ul>
<li>pip 패키지 설치하기</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo pip install /tmp/tensorflow_pkg/tensorflow-1.0.0-py2-none-any.whl #python2버전</div><div class="line">sudo pip3 install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp36-cp36m-macosx_10_12_x86_64.whl #python3버전</div></pre></td></tr></table></figure>
<p>이건 설정에 따라서 다르닌깐요<br>sudo pip(파이썬3이면 pip3) install /tmp/tensorflow_pkg/ 한다음에 tab키 쳐주시면 뜨는데 그리고 엔터 눌러주세요.</p>
<h1 id="끝"><a href="#끝" class="headerlink" title="끝!"></a>끝!</h1><p>이제 끝났습니다.<br>이제 저런 오류없이 텐서플로우가 작동할 것입니다.<br>긴 글 읽어주셔서 고맙습니다.<br><a href="https://www.tensorflow.org/install/install_sources" rel="external nofollow noopener noreferrer" target="_blank">https://www.tensorflow.org/install/install_sources</a> 를 참고하여 작성한 문서입니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우-1-0을-pip으로-설치하고-사용하면-일어나는-오류&quot;&gt;&lt;a href=&quot;#텐서플로우-1-0을-pip으로-설치하고-사용하면-일어나는-오류&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우 1.0을 pip으로 설치하고 사용
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="App" scheme="https://deeptensorflow.github.io/categories/Tensorflow/App/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="install" scheme="https://deeptensorflow.github.io/tags/install/"/>
    
      <category term="bazel" scheme="https://deeptensorflow.github.io/tags/bazel/"/>
    
  </entry>
  
  <entry>
    <title>최고의 머신러닝, 텐서플로우 초보용 무료강의를 소개합니다.</title>
    <link href="https://deeptensorflow.github.io/2017/02/18/sung-hun-kim-ml-lecture/"/>
    <id>https://deeptensorflow.github.io/2017/02/18/sung-hun-kim-ml-lecture/</id>
    <published>2017-02-18T12:49:50.000Z</published>
    <updated>2017-02-18T12:56:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝이-무엇인지-모른다면"><a href="#머신러닝이-무엇인지-모른다면" class="headerlink" title="머신러닝이 무엇인지 모른다면?"></a>머신러닝이 무엇인지 모른다면?</h1><p>이전 포스팅을 봐주세요.</p>
<h1 id="최고의-입문용-강의를-소개합니다"><a href="#최고의-입문용-강의를-소개합니다" class="headerlink" title="최고의 입문용 강의를 소개합니다."></a>최고의 입문용 강의를 소개합니다.</h1><p>홍공 과기대의 김성훈 교수님이 진행하는 “모두를 위한 머신러닝과 딥러닝 강의”를 소개합니다.<br>입문용 강의로는 정말 최고라고 생각됩니다.<br>머신러닝에 대한 기초 알고리즘부터 텐서플로우로 응용까지 자세히 설명해 주셨습니다.<br>수학이나 프로그래밍에 대한 기초가 없어도 편하게 들을 수 있습니다.<br>(단, 파이썬은 아주 약간은 알아야 합니다.)<br>파이썬을 아예 모르신다면 <a href="https://wikidocs.net/book/1" rel="external nofollow noopener noreferrer" target="_blank">https://wikidocs.net/book/1</a> 에서 무료로 공부하시는 것을 추천드립니다.<br>자, 시범 강의 하나만 띄우겠습니다.<br><div class="video-container"><iframe src="//www.youtube.com/embed/dZ4vw6v3LcA" frameborder="0" allowfullscreen></iframe></div><br>매우 재미있겠지요?<br>아주 쉽게 차근차근 잘 설명해주시니 기초지식이 없어도 두려워하지 마세요.<br><a href="https://hunkim.github.io/ml/" rel="external nofollow noopener noreferrer" target="_blank">https://hunkim.github.io/ml/</a> 로 가면 김성훈 교수님의 모든 강의를 무료로 볼 수 있습니다.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;머신러닝이-무엇인지-모른다면&quot;&gt;&lt;a href=&quot;#머신러닝이-무엇인지-모른다면&quot; class=&quot;headerlink&quot; title=&quot;머신러닝이 무엇인지 모른다면?&quot;&gt;&lt;/a&gt;머신러닝이 무엇인지 모른다면?&lt;/h1&gt;&lt;p&gt;이전 포스팅을 봐주세요.&lt;/p
    
    </summary>
    
      <category term="Machinelearning" scheme="https://deeptensorflow.github.io/categories/Machinelearning/"/>
    
      <category term="Lecture" scheme="https://deeptensorflow.github.io/categories/Machinelearning/Lecture/"/>
    
    
      <category term="machinelearning" scheme="https://deeptensorflow.github.io/tags/machinelearning/"/>
    
      <category term="lecture" scheme="https://deeptensorflow.github.io/tags/lecture/"/>
    
  </entry>
  
  <entry>
    <title>왜 머신러닝은 주목받을까? 머신러닝이 무엇인지 알아보자.</title>
    <link href="https://deeptensorflow.github.io/2017/02/18/why-machinelearning-is-appeared/"/>
    <id>https://deeptensorflow.github.io/2017/02/18/why-machinelearning-is-appeared/</id>
    <published>2017-02-18T12:15:56.000Z</published>
    <updated>2017-02-19T03:52:48.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="머신러닝이-세상에-나오게-된-계기"><a href="#머신러닝이-세상에-나오게-된-계기" class="headerlink" title="머신러닝이 세상에 나오게 된 계기"></a>머신러닝이 세상에 나오게 된 계기</h1><p><img src="https://deeptensorflow.github.io/images/ml1.png" alt="machinelearning_1"><br>본래 프로그래머들이 프로그래밍을 짜는 방법은 일일이 가르쳐주는 방식이었습니다.<br>입력값이 0일때는 작동을 중지하고 입력값이 1일때는 작동을 시작하고 이런 방식이었죠.<br>그러다가 프로그래머들은 다음과 같은 호기심이 생깁니다.<br>“프로그램이 인간처럼 학습할 수 있을까?”<br>많은 오류들을 거쳐(이 오류들을 해결하는 과정이 상당히 재밌는데 다음에 다루겠습니다.) 결국 기계를 인간처럼 학습시키는데 성공하게 되고 이러한 프로그래밍을 머신러닝이라고 부르게 됩니다.</p>
<h1 id="머신러닝은-무엇이-좋은가"><a href="#머신러닝은-무엇이-좋은가" class="headerlink" title="머신러닝은 무엇이 좋은가?"></a>머신러닝은 무엇이 좋은가?</h1><p>머신러닝의 장점은 인간처럼 행동할 수 있다는 것입니다.<br>원래는 우리는 기계에게 수많은 rule들을 제시해가며 행동을 가르쳤습니다.<br>하지만 인간을 떠올린다면 인간은 무엇이 착한일이고 무엇이 나쁜일인지 어떻게 알게 되었을까요?<br>무슨 행동을 일단 해보고 혼나면 나쁜일, 칭찬을 들으면 착한일이라고 알지 않았을까요?<br>머신러닝을 적용하면 기계도 마찬가지로 행동을 할 수 있게 됩니다.<br>우선 시험 데이터를 모아서 정답 데이터와 비교를 해봅니다.<br>이렇게 시험 학습된 기계는 따로 인간이 rule을 정해주지 않아도 다음부터는 데이터가 들어오면 알아서 학습한 내용을 바탕으로 행동을 할 수 있게 됩니다.<br>예를들어 사진 판별, 언어번역, 자동운전 등을 생각해 봅시다.<br>일일히 규칙들을 정해준다면 얼마나 복잡할까요?<br>그리고 새로운 규칙들이 매번 생겨나는 경우들도 있지요.<br>이러한 경우에 머신러닝을 도입하면 상당히 프로그래밍이 쉽고 정교하게 됩니다.</p>
<h1 id="머신러닝의-미래"><a href="#머신러닝의-미래" class="headerlink" title="머신러닝의 미래"></a>머신러닝의 미래</h1><p>현재 구글이 tensorflow를 발표하고 머신러닝 1등 라이브러리로 우뚝 섰습니다.<br>텐서플로우로 인해서 프로그래밍을 모르는 일반인들도 한달정도만 공부를 해도 어느정도 머신러닝을 활용할 수 있게 되어 진입장벽이 매우 낮아졌습니다.<br>그리고 현재 우리나라는 비교적 소극적이지만 미국, 중국에서는 고액 연봉을 제시하며 서로 머신러닝 관련 프로그래머들을 영입하고 있습니다.<br>점점 머신러닝을 자신들의 제품에 도입하는 경우도 늘어가고 있지요.<br>머신러닝의 미래는 밝습니다!<br>그리고 누구나 머신러닝을 사용할 수 있습니다!</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;머신러닝이-세상에-나오게-된-계기&quot;&gt;&lt;a href=&quot;#머신러닝이-세상에-나오게-된-계기&quot; class=&quot;headerlink&quot; title=&quot;머신러닝이 세상에 나오게 된 계기&quot;&gt;&lt;/a&gt;머신러닝이 세상에 나오게 된 계기&lt;/h1&gt;&lt;p&gt;&lt;img s
    
    </summary>
    
      <category term="Machinelearning" scheme="https://deeptensorflow.github.io/categories/Machinelearning/"/>
    
      <category term="News" scheme="https://deeptensorflow.github.io/categories/Machinelearning/News/"/>
    
    
      <category term="machinelearning" scheme="https://deeptensorflow.github.io/tags/machinelearning/"/>
    
  </entry>
  
  <entry>
    <title>텐서플로우 1.0(최신버전) 설치하는 방법</title>
    <link href="https://deeptensorflow.github.io/2017/02/18/install-tensorflow/"/>
    <id>https://deeptensorflow.github.io/2017/02/18/install-tensorflow/</id>
    <published>2017-02-18T09:56:35.000Z</published>
    <updated>2017-02-19T01:12:01.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="텐서플로우-설치"><a href="#텐서플로우-설치" class="headerlink" title="텐서플로우 설치"></a>텐서플로우 설치</h1><p>텐서플로우 1.0버전이 출시되었습니다~<br>API변동이 약간 있는 것으로 파악되며 앞으로 텐서플로우1.0을 분석하여 블로그를 작성해보도록 하겠습니다.<br>텐서플로우 공식 홈페이지에서 권장하는 방식인 virtualenv로 설치하는 방법을 택하였습니다.<br>virtualenv를 사용하면 다른 python 프로그램들에 간섭하거나 영향받는 일이 없어집니다.</p>
<h2 id="텐서플로우-MAC-설치"><a href="#텐서플로우-MAC-설치" class="headerlink" title="텐서플로우 MAC 설치"></a>텐서플로우 MAC 설치</h2><ul>
<li>homebrew 설치</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</div></pre></td></tr></table></figure>
<p>homebrew는 mac의 패키지 관리자입니다.</p>
<ul>
<li>python3 설치</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install python3</div></pre></td></tr></table></figure>
<ul>
<li>virtualenv 설치</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install virtualenv</div></pre></td></tr></table></figure>
<ul>
<li>virtualenv 환경 세팅(tensorflow 폴더)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">virtualenv tensorflow</div><div class="line">source tensorflow/bin/activate</div><div class="line">cd tensorflow</div></pre></td></tr></table></figure>
<ul>
<li>tensorflow 최신버전 설치(cpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow</div></pre></td></tr></table></figure>
<ul>
<li>tensorflow 최신버전 설치(gpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow-gpu</div></pre></td></tr></table></figure>
<ul>
<li>설치에 실패한 경우</li>
</ul>
<p>pip3 버전이 8.1이하인 경우일 것입니다.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew upgrade python3</div></pre></td></tr></table></figure><br>해주시고 다시 처음부터 진행해 주시기 바랍니다.</p>
<ul>
<li>가상환경을 종료하고 싶은경우</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deactivate</div></pre></td></tr></table></figure>
<h2 id="텐서플로우-LINUX-설치"><a href="#텐서플로우-LINUX-설치" class="headerlink" title="텐서플로우 LINUX 설치"></a>텐서플로우 LINUX 설치</h2><ul>
<li>python3 설치</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get install python3</div></pre></td></tr></table></figure>
<ul>
<li>virtualenv 설치</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install virtualenv</div></pre></td></tr></table></figure>
<ul>
<li>virtualenv 환경 세팅(tensorflow 폴더)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">virtualenv tensorflow</div><div class="line">source tensorflow/bin/activate</div><div class="line">cd tensorflow</div></pre></td></tr></table></figure>
<ul>
<li>tensorflow 최신버전 설치(cpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow</div></pre></td></tr></table></figure>
<ul>
<li>tensorflow 최신버전 설치(gpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow-gpu</div></pre></td></tr></table></figure>
<ul>
<li>설치에 실패한 경우</li>
</ul>
<p>pip3 버전이 8.1이하인 경우일 것입니다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo apt-get upgrade python3</div></pre></td></tr></table></figure>
<p>해주시고 다시 처음부터 진행해 주시기 바랍니다.</p>
<ul>
<li>가상환경을 종료하고 싶은경우</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">deactivate</div></pre></td></tr></table></figure>
<h2 id="텐서플로우-WINDOW-설치"><a href="#텐서플로우-WINDOW-설치" class="headerlink" title="텐서플로우 WINDOW 설치"></a>텐서플로우 WINDOW 설치</h2><ul>
<li>python 3.5 설치</li>
</ul>
<p>다른 운영체제와 다르게 3.6버전을 아직 지원하지 않으니 주의 바랍니다.<br><a href="https://www.python.org/downloads/release/python-352/" rel="external nofollow noopener noreferrer" target="_blank">https://www.python.org/downloads/release/python-352/</a><br>위의 링크에서 3.5버전을 다운받으시기 바랍니다.</p>
<ul>
<li>tensorflow 최신버전 설치(cpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow</div></pre></td></tr></table></figure>
<ul>
<li>tensorflow 최신버전 설치(gpu버전)</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip3 install --upgrade tensorflow-gpu</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;텐서플로우-설치&quot;&gt;&lt;a href=&quot;#텐서플로우-설치&quot; class=&quot;headerlink&quot; title=&quot;텐서플로우 설치&quot;&gt;&lt;/a&gt;텐서플로우 설치&lt;/h1&gt;&lt;p&gt;텐서플로우 1.0버전이 출시되었습니다~&lt;br&gt;API변동이 약간 있는 것으로 파악되며
    
    </summary>
    
      <category term="Tensorflow" scheme="https://deeptensorflow.github.io/categories/Tensorflow/"/>
    
      <category term="App" scheme="https://deeptensorflow.github.io/categories/Tensorflow/App/"/>
    
    
      <category term="tensorflow" scheme="https://deeptensorflow.github.io/tags/tensorflow/"/>
    
      <category term="install" scheme="https://deeptensorflow.github.io/tags/install/"/>
    
  </entry>
  
</feed>
