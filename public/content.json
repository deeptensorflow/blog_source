{"meta":{"title":"Tensorflow Internal","subtitle":"All about tensorflow","description":"Talk about tensorflow internal. And IT.","author":"MyeongsooKim","url":"https://deeptensorflow.github.io"},"pages":[],"posts":[{"title":"초보자를 위한 MNIST(텐서플로우)","slug":"mnist-for-beginners","date":"2017-02-28T00:17:40.000Z","updated":"2017-02-28T02:54:57.000Z","comments":true,"path":"2017/02/28/mnist-for-beginners/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/28/mnist-for-beginners/","excerpt":"","text":"이 글은 https://www.tensorflow.org/get_started/mnist/beginners 공식 홈페이지 내용을 번역한 것이 주 내용입니다. MNIST란 무엇일까?MNIST란 본래 미국에서 우편번호를 분류할때 기계에게 분류를 맡기려는 시도에서 비롯되었습니다.MNIST는 간단한 컴퓨터 시각 데이터 세트입니다.이것은 다음과 같은 자필 자릿수의 이미지로 구성됩니다.또한 각 이미지의 레이블을 포함하여 어떤 숫자인지 알려줍니다.예를 들어 위 이미지의 레이블은 5, 0, 4 및 1입니다.이 자습서에서는 이미지를보고 어떤 자릿수인지 예측하는 모델을 교육 할 것입니다.우리의 목표는 최첨단 성능을 구현하는 매우 정교한 모델을 교육하는 것이 아닙니다.우리는 Softmax Regression이라 불리는 매우 간단한 모델로 시작할 것입니다.이 자습서의 실제 코드는 매우 짧으며 모든 흥미로운 내용은 단 3 줄에서 발생합니다.그러나 TensorFlow가 작동하는 방법과 핵심 기계 학습 개념 모두에 대한 아이디어를 이해하는 것이 매우 중요합니다. 이 튜토리얼에서 우리가 달성 할 수있는 것 : MNIST 데이터와 softmax 회귀에 대해 알게 될 것입니다. 이미지의 모든 픽셀을 보면서 숫자를 인식하는 모델 인 함수를 만들 것입니다. TensorFlow를 사용하여 수천 가지 예제를 “훑어보고”숫자를 인식하도록 모델을 교육합니다(첫 번째 TensorFlow 세션을 실행하여 수행). 테스트 데이터로 모델의 정확성을 확인할 것입니다. MNIST 데이터는 Yann LeCun의 웹 사이트 에서 호스팅됩니다.이 자습서의 코드를 복사하여 붙여 넣는 경우 다음 두 줄의 코드를 사용하여 데이터를 자동으로 다운로드하고 읽습니다. 12from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True) MNIST 데이터는 훈련 데이터(mnist.train) 55,000개, 테스트 데이터(mnist.test) 10,000개, 및 검증 데이터(mnist.validation) 5,000개 세 부분으로 나누어집니다.이 분할은 매우 중요하며 기계 학습에서 필수적입니다.이미 트레이닝을 한 데이터에 대해서 검증을 하고 테스트를 하는 것은 의미가 없겠죠?꼭 나누어주세요!MNIST데이터는 두가지로 분류되어 있습니다.손으로 직접 쓴 글씨와 그에 해당하는 라벨 데이터로 나누어져 있습니다.트레이닝 이미지는 mnist.train.images이고 트레이닝 레이블은 mnist.train.labels입니다.트레이닝 세트와 테스트 세트에는 이미지와 해당 레이블이 포함되어 있습니다.이 배열을 28x28 = 784 숫자의 벡터로 전개 할 수 있습니다.이 배열을 1열로 펼친다면 784개의 숫자로 이루어진 데이터가 되겠죠?55000개의 데이터를 테스트 데이터로 쓸 때 [55000,784] 배열꼴의 데이터를 쓴다면 MNIST데이터 55000의 데이터를 모을 수 있는 꼴이 될 것입니다.첫 번째 차원은 이미지 목록에 대한 인덱스이고 두 번째 차원은 각 이미지의 각 픽셀에 대한 인덱스입니다.MNIST의 각 이미지에는 이미지에 그려지는 숫자를 나타내는 0에서 9 사이의 숫자가 해당 레이블을 가지고 있습니다.이 튜토리얼의 목적을 위해 우리는 레이블을 “원 핫 벡터 (one-hot vectors)”로 할 것입니다.원 핫 벡터는 대부분 차원에서 0이고 단일 차원에서 1 인 벡터입니다.이 경우,n번째 자릿수는 n차원 벡터로 표현됩니다.예를 들어, 3은 [0,0,0,1,0,0,0,0,0,0] 입니다.자, 이제 softmax를 통해서 분석할 일만 남았습니다. softmax란? 우리는 이미지를보고 각 숫자가 될 확률을 줄 수 있기를 원합니다. 예를 들어, 우리 모델은 9의 그림을보고 80%의 확률로 9라고 확신 할 수 있지만, 다른 모든 것들에도 약간의 확률이 있습니다(합계 20%). 100% 확실하지는 않습니다. 이렇게 각 숫자에 대한 확률로 나타내주는 쉬운 방법이 softmax 회귀분석을 쓰는 방법입니다. Softmax 회귀 분석을 하는 과정을 아래에서 보여드리겠습니다. 우선 [55000, 784] 행렬의 데이터가 들어올 것입니다(55000개의 MNIST데이터셋). 그리고 이 데이터셋은 [784,10]꼴의 행렬과 곱해지게 될 것입니다(weight의 개념으로). 그리고는 [10]꼴의 행렬과 더해질 것입니다(bias의 개념으로). 그러면 각 데이터셋에 대해서 [10]꼴의 배열에 임의의 숫자가 나오겠지요? 그것을 softmax로 처리하면 각각 10개의 데이터가 0~1사이의 데이터로 변합니다. 그 10개의 데이터값을 다 합한뒤 각각의 데이터에 나누어준다면 그것이 확률이 되는 것입니다. 텐서플로우를 이용해 MNIST를 분석해보자!이전의 포스팅에서 설명드렸던 placeholder를 이용해 값을 유동적으로 받기 위한 x를 선언하겠습니다.1x = tf.placeholder(tf.float32, [None, 784]) 위의 코드에서 None에는 데이터의 개수가 올 것입니다. 그리고 위에서 설명한대로 softmax를 정의하기 위해서 [784,10] 꼴의 weight와 [10]꼴의 bias가 필요합니다.12W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10])) 그럼 이제 x값에 weight와 bias를 더하고 softmax를 취해줘야겠죠?텐서플로우에서는 이것이 한줄로 가능합니다. 자, 이제 데이터를 받고 softmax를 적용시킬 준비가 끝났습니다. 트레이닝 시키기우리는 우선 트레이닝을 시키기 위해서 손실함수를 작성해야합니다.이는 모델이 원하는 결과와 얼마나 멀리 떨어져 있는지 나타냅니다.우리는 손실함수를 최소화하려고 노력하며, 손실함수 마진이 작을수록 모델이 더 좋습니다.어렵게 생각하지 마세요!손실함수는 그냥 실제 값과 우리의 예측값이 얼마나 다른지 알 수 있게 해주는 함수입니다.여기서는 인기있는 손실함수인 cross-entropy라는 것을 써보겠습니다.자세한 것은 모르셔도 되고 그냥 실제 값과 예측 값의 차이를 표현하는 한 방식이라고 보시면 됩니다.y 값은 예측 값입니다.y_ 값이 실제 값입니다.123y = tf.nn.softmax(tf.matmul(x,W)+b)y_ = tf.placeholder(tf.float32, [None, 10])cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y), reduction_indices=[1])) 그런 다음 이 손실함수를 통해서 예측값과 실제값의 차이를 알았으니 차이를 좁혀주기 위해서 학습을 시켜야겠지요?GradientDescentOptimizer 라는 기본적인 알고리즘으로 학습을 시켜보겠습니다.마찬가지로 이 알고리즘이 어떤식으로 동작하는지 모르더라도 텐서플로우에서 제공하는 API를 쓰면 손쉽게 적용할 수 있습니다.1train = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) 이제 반복문으로 이 트레인함수를 돌려주면 됩니다.mnist.train.nextbatch는 텐서플로우에서 제공해주는 기본 API입니다.데이터를 100개씩 랜덤으로 뽑아줍니다.그리고 placeholder로 x와 y를 선언했기 때문에 데이터를 읽어서 바로 x와 y_에 넣어줄 수 있습니다.그런뒤 위의 손실함수를 GradientDescentOptimizer로 최소화시켜주는 것입니다(train).123456sess = tf.InteractiveSession()tf.global_variables_initializer().run()for _ in range(1000): batch_xs, batch_ys = mnist.train.next_batch(100) sess.run(train, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) 모델 평가하기자, 이렇게 훈련시킨 모델이 얼마나 잘 학습되었는지 확인해봐야겠죠?softmax를 거친 우리 기대값 배열은 0~9사이의 숫자가 나올 확률을 계산해 두었을 것입니다.그렇다면 확률이 가장 높게 나온 label이 우리의 예측 숫자가 될 것입니다.테스트 데이터를 넣고 정확도를 평균내어봅시다.1234correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) 정확도가 몇퍼센트가 나오시나요?제 코드를 기준으로는 91.4프로가 나옵니다.다음에는 이 정확도를 99프로 이상으로 끌어올려보도록 하겠습니다.","categories":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://deeptensorflow.github.io/categories/TensorFlow/"},{"name":"App","slug":"TensorFlow/App","permalink":"https://deeptensorflow.github.io/categories/TensorFlow/App/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"MNIST","slug":"MNIST","permalink":"https://deeptensorflow.github.io/tags/MNIST/"}]},{"title":"텐서플로우 맛보기(기본 가이드)","slug":"tensorflow-tasting","date":"2017-02-26T23:35:14.000Z","updated":"2017-02-27T12:20:58.000Z","comments":true,"path":"2017/02/27/tensorflow-tasting/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/27/tensorflow-tasting/","excerpt":"","text":"이 문서는 https://www.tensorflow.org/get_started/get_started 의 내용을 번역했습니다. 텐서플로우를 하기 전에 알아야 할것 파이썬 프로그래밍 배열에 관한 내용 (조금이라도) 머신러닝에 관한 내용 (조금이라도) 참고로 파이썬은 https://wikidocs.net/book/1 이곳에서 공부하시는 것을 추천드립니다.TensorFlow는 여러 API를 제공합니다.최저 수준의 API 인 TensorFlow Core는 완벽한 프로그래밍 제어 기능을 제공합니다.TensorFlow Core는 기계 학습 연구자 및 모델을 정밀하게 제어해야하는 사람들에게 권장됩니다.높은 수준의 API는 TensorFlow Core 위에 구축됩니다.이러한 상위 수준의 API는 일반적으로 TensorFlow Core보다 배우고 사용하기가 쉽습니다.또한 상위 수준의 API는 반복적인 작업을 여러 사용자간에 보다 쉽고 일관되게 만듭니다.tf.contrib.learn과 같은 고급 API를 사용하면 데이터 세트, 견적 도구, 교육 및 추론을 관리 할 수 ​​있습니다.상위 수준 TensorFlow API 중 일부 (메소드 이름이 포함 contrib)는 아직 개발 중입니다.contrib이후의 TensorFlow 릴리스에서 일부 메서드가 변경되거나 더 이상 사용되지 않을 수도 있습니다. 텐서란?TensorFlow에서 데이터의 중심 단위는 텐서 입니다.텐서는 임의의 수의 차원으로 배열된 값들의 집합으로 구성됩니다.텐서의 랭크는 차원의 개수입니다.다음은 텐서(tensors)의 몇 가지 예입니다.12343 # a rank 0 tensor; this is a scalar with shape [][1. ,2., 3.] # a rank 1 tensor; this is a vector with shape [3][[1., 2., 3.], [4., 5., 6.]] # a rank 2 tensor; a matrix with shape [2, 3][[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3] 텐서플로우 CORE 텐서플로우 가져오기 TensorFlow 프로그램에 대한 표준 import 문은 다음과 같습니다.1import tensorflow as tf 이렇게하면 파이썬은 TensorFlow의 모든 클래스, 메소드 및 심볼에 액세스 할 수 있습니다.대부분의 문서에서는 이미 이 작업을 수행했다고 가정합니다. 연산 그래프 TensorFlow Core 프로그램은 두 개의 개별 섹션으로 구성되어 있다고 생각할 수 있습니다. 연산 그래프 작성. 연산 그래프를 실행합니다.연산 그래프는 노드의 그래프로 배열 TensorFlow의 일련의 동작입니다.간단한 전산 그래프를 작성해 봅시다.각 노드는 0개 이상의 텐서를 입력으로 사용하고 출력으로도 생성합니다.상수도 노드중 하나의 유형입니다.TensorFlow 상수는 input과 output이 없으며 내부적으로 저장하는 값을 출력합니다.node1과 node2라는 두개의 텐서를 만들어보겠습니다.123node1 = tf.constant(3.0, tf.float32)node2 = tf.constant(4.0) # also tf.float32 implicitlyprint(node1, node2) 결과는 아래와 같습니다.1Tensor(&quot;Const:0&quot;, shape=(), dtype=float32) Tensor(&quot;Const_1:0&quot;, shape=(), dtype=float32) 우리의 예상과는 다른 결과가 나왔습니다.3.0과 4.0이 나올줄 알았는데 이상한 상태를 가르키는듯한 문구만 나왔습니다.우리가 원하는 값을 출력하려면 세션을 주고 실행을 시켜야 합니다.아래의 내용을 추가해봅시다.12sess = tf.Session()print(sess.run([node1, node2])) Tensor노드를 연산과 결합 하여보다 복잡한 계산을 할 수 있습니다 (연산도 노드입니다).예를 들어 두 개의 상수 노드를 추가하고 다음과 같이 새 그래프를 생성 할 수 있습니다. 123node3 = tf.add(node1, node2)print(&quot;node3: &quot;, node3)print(&quot;sess.run(node3): &quot;,sess.run(node3)) 출력 결과값은 아래와 같습니다. 12node3: Tensor(&quot;Add_2:0&quot;, shape=(), dtype=float32)sess.run(node3): 7.0 텐서보드 TensorFlow는 전산 그래프의 그림을 표시 할 수있는 TensorBoard라는 유틸리티를 제공합니다.다음은 TensorBoard가 그래프를 시각화하는 방법을 보여주는 스크린 샷입니다.데이터가 많아지면 일일히 정보를 확인하는 것이 어려울 수 있습니다.텐서보드를 이용하면 원하는 데이터를 한눈에 볼 수 있습니다. placeholder placeholder는 나중에 값을 채워주겠다고 하고 우선 형식만 선언해 두는 형태입니다.아래와 같이 연산을 지정해 준 뒤에 feed_dict 매개 변수를 사용하여 이러한 입력란에 구체적인 값을 제공하는 Tensors를 지정하여 이 그래프를 여러 입력으로 평가할 수 있습니다.12345678910import tensorflow as tfa = tf.placeholder(tf.float32)b = tf.placeholder(tf.float32)tf_add = a + bsess = tf.Session()print(sess.run(tf_add, feed_dict= &#123;a : [1,2], b: [3,4]&#125;)) 학습 시키기 머신러닝 라이브러리인 만큼 당연히 모델을 만들고 학습을 시킬 수 있는 방법도 제공하고 있습니다.모델을 학습 가능하게 만들려면 동일한 입력으로 새로운 출력을 얻기 위해 그래프를 수정할 수 있어야합니다.변수를 사용하면 그래프에 학습 가능한 매개 변수를 추가 할 수 있습니다.그것들은 타입과 초기 값으로 구성됩니다. 우선 처음에는 아래와 같이 평가 모델을 작성합니다.12345678910111213141516import tensorflow as tfW = tf.Variable([.3], tf.float32)b = tf.Variable([.3], tf.float32)x = tf.placeholder(tf.float32)Y = W * x + binit = tf.global_variables_initializer()sess = tf.Session()sess.run(init)print(sess.run(Y, feed_dict= &#123;x : [1., 2., 3., 4.]&#125;)) 상수는 호출 할 때 초기화되며 tf.constant값은 절대로 변경 될 수 없습니다.반대로 변수(tf.Variable)는 초기화 할 때 초기화되지 않습니다.TensorFlow 프로그램의 모든 변수를 초기화하려면 다음과 같이 명시적으로 특수 작업(tf.global_variables_initializer())을 호출해야합니다. 우리는 모델을 만들었지만 아직 얼마나 좋은지 모릅니다.교육 데이터에 대한 모델을 평가하려면 원하는 값을 제공하기 위한 목표값이 필요하며 손실 함수를 작성해야합니다.손실 함수는 목표값으로부터 현재 모델이 얼마나 떨어져 있는지를 측정합니다.현재 모델과 목표값 사이의 델타의 제곱을 합한 선형 회귀에 표준 손실 모델을 사용합니다.즉, 기대값과 목표값의 차를 제곱한 값을 손실 모델로 작성합니다.1234567891011121314151617import tensorflow as tfW = tf.Variable([.3], tf.float32)b = tf.Variable([.3], tf.float32)x = tf.placeholder(tf.float32)_y = tf.placeholder(tf.float32)Y = W * x + bloss = tf.reduce_sum(tf.square(Y-_y))init = tf.global_variables_initializer()sess = tf.Session()sess.run(init)print(sess.run(loss, feed_dict= &#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;)) 우리는 tf.assign을 통해 tf.Variable로 선언된 변수에 대해서 수동으로 값을 바꾸어 줄 수 있습니다.예를들어 위의 모델은 W가 -1, b가 1 일때 손실 함수가 0이 되어 최적의 매개변수가 됩니다.아래와 같이 모델을 작성할 수 있습니다.12345678910111213141516171819202122import tensorflow as tfW = tf.Variable([.3], tf.float32)b = tf.Variable([.3], tf.float32)x = tf.placeholder(tf.float32)_y = tf.placeholder(tf.float32)Y = W * x + bloss = tf.reduce_sum(tf.square(Y-_y))init = tf.global_variables_initializer()sess = tf.Session()sess.run(init)fixW = tf.assign(W, [-1])fixb = tf.assign(b, [1])sess.run([fixW, fixb])print(sess.run(loss, feed_dict= &#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;)) print값은 0이 됩니다.우리는 Wand 의 “완벽한”값을 추측 b했지만 기계 학습의 요점은 올바른 모델 매개 변수를 자동으로 찾는 것입니다.다음 섹션에서 이를 수행하는 방법을 보여줄 것입니다. 트레이닝 시키기 텐서플로우에서는 손실함수의 값을 최소화 시키기 위해서 여러 optimizer들을 제공합니다.이들을 간단한 API로 손실함수를 최소화 시킵니다.가장 간단한 예는 gradient descent optimizer입니다.12345678910111213141516171819202122import tensorflow as tfW = tf.Variable([.3], tf.float32)b = tf.Variable([.3], tf.float32)x = tf.placeholder(tf.float32)_y = tf.placeholder(tf.float32)Y = W * x + bloss = tf.reduce_sum(tf.square(Y-_y))init = tf.global_variables_initializer()optimizer = tf.train.GradientDescentOptimizer(0.01)train = optimizer.minimize(loss)sess = tf.Session()sess.run(init)for i in range(1000): sess.run(train, feed_dict=&#123;x : [1, 2, 3, 4], _y : [0, -1, -2, -3]&#125;)print(sess.run([W, b])) 위와 같은 방법으로 자동으로 W, b를 학습시킬 수 있습니다. tf.contrib.learntf.contrib.learn는 기계 학습의 메커니즘을 단순화하는 고급 TensorFlow 라이브러리입니다.평가관련 반복문 관리, 트레이닝 관련 반복문 관리, 데이터셋 관리, feeding관리를 포함합니다.tf.contrib.learn은 많은 공통 모델을 정의합니다. linear regression코드에 이를 적용하면 아래와 같이 간결해집니다.123456789101112131415161718192021222324252627282930import tensorflow as tf# NumPy is often used to load, manipulate and preprocess data.import numpy as np# Declare list of features. We only have one real-valued feature. There are many# other types of columns that are more complicated and useful.features = [tf.contrib.layers.real_valued_column(&quot;x&quot;, dimension=1)]# An estimator is the front end to invoke training (fitting) and evaluation# (inference). There are many predefined types like linear regression,# logistic regression, linear classification, logistic classification, and# many neural network classifiers and regressors. The following code# provides an estimator that does linear regression.estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)# TensorFlow provides many helper methods to read and set up data sets.# Here we use `numpy_input_fn`. We have to tell the function how many batches# of data (num_epochs) we want and how big each batch should be.x = np.array([1., 2., 3., 4.])y = np.array([0., -1., -2., -3.])input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;&quot;x&quot;:x&#125;, y, batch_size=4, num_epochs=1000)# We can invoke 1000 training steps by invoking the `fit` method and passing the# training data set.estimator.fit(input_fn=input_fn, steps=1000)# Here we evaluate how well our model did. In a real example, we would want# to use a separate validation and testing data set to avoid overfitting.estimator.evaluate(input_fn=input_fn) 커스텀모델 만들기tf.contrib.learn는 함수정의부분을 수정할 수 있습니다.TensorFlow에 내장되어 있지 않은 커스텀 모델을 만들고 싶다고 가정 해 보겠습니다.우리는 여전히 높은 수준의 반복문 관리, 트레이닝 관련 반복문 관리, 데이터셋 관리, feeding관리를 유지할 수 있습니다.설명을 위해, 우리는 저수준 TensorFlow API에 대한 지식을 사용하여 LinearRegressor에 대한 자체 모델을 구현하는 방법을 보여줄 것입니다.tf.contrib.learn.Estimator를 써서 개발해 보도록 하겠습니다.tf.contrib.learn.LinearRegressor는 tf.contrib.learn.Estimator의 sub-class입니다.Estimator에게 예측, 교육 단계 및 손실을 평가할 수있는 방법을 tf.contrib.learn에 알리는 function_fn이라는 기능을 제공하기 만하면됩니다.아래의 코드가 그 예제입니다. 1234567891011121314151617181920212223242526272829303132import numpy as npimport tensorflow as tf# Declare list of features, we only have one real-valued featuredef model(features, labels, mode): # Build a linear model and predict values W = tf.get_variable(&quot;W&quot;, [1], dtype=tf.float64) b = tf.get_variable(&quot;b&quot;, [1], dtype=tf.float64) y = W*features[&apos;x&apos;] + b # Loss sub-graph loss = tf.reduce_sum(tf.square(y - labels)) # Training sub-graph global_step = tf.train.get_global_step() optimizer = tf.train.GradientDescentOptimizer(0.01) train = tf.group(optimizer.minimize(loss), tf.assign_add(global_step, 1)) # ModelFnOps connects subgraphs we built to the # appropriate functionality. return tf.contrib.learn.ModelFnOps( mode=mode, predictions=y, loss= loss, train_op=train)estimator = tf.contrib.learn.Estimator(model_fn=model)# define our data setx=np.array([1., 2., 3., 4.])y=np.array([0., -1., -2., -3.])input_fn = tf.contrib.learn.io.numpy_input_fn(&#123;&quot;x&quot;: x&#125;, y, 4, num_epochs=1000)# trainestimator.fit(input_fn=input_fn, steps=1000)# evaluate our modelprint(estimator.evaluate(input_fn=input_fn, steps=10))","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"App","slug":"Tensorflow/App","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/App/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"}]},{"title":"텐서플로우에 새로운 연산 추가하기(커스터마이징)","slug":"add-new-operation-on-tensorflow","date":"2017-02-21T13:24:53.000Z","updated":"2017-02-23T20:02:39.000Z","comments":true,"path":"2017/02/21/add-new-operation-on-tensorflow/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/21/add-new-operation-on-tensorflow/","excerpt":"","text":"텐서플로우를 이용해서 소스코드를 작성하다보면 가끔 내가 만든 연산을 추가하고 싶다는 생각이 듭니다.이럴 경우에 텐서플로우에서는 operation을 추가하는 방법을 공식홈페이지에서 설명해주고 있습니다.https://www.tensorflow.org/extend/adding_an_op하지만 영어로 되어있기에… 개인 저장용으로 operation을 텐서플로우에 추가하는 방법을 적어보고자 합니다. operation 추가하기기존 TensorFlow 라이브러리에서 다루지 않는 연산을 만들려면 먼저 파이썬에서 연산을 기존 파이썬 연산이나 함수의 조합으로 작성하는 것이 좋습니다.이것이 가능하지 않으면 사용자 정의 C ++ op를 작성할 수 있습니다.사용자 정의 C ++ 연산을 작성하는 데에는 여러 가지 이유가 있습니다. 기존 작업의 구성으로 작업을 표현하는 것이 쉽지 않거나 가능하지 않은 경우 기존 기본 요소의 구성으로 작업을 표현하는 것은 효율적이지 않은 경우 원래 있던 기존의 요소들을 미래의 컴파일러가 융합하기 힘들어하는 경우즉, 왠만하면 기존의 텐서플로우 op로 연산을 하되 기존의 op로 연산이 불가능하거나 효율적이지 않은 경우 본인의 op를 직접 추가하라는 말입니다. 맞춤 작업을 통합하려면 다음 작업이 필요합니다. 새로운 op를 C ++ 파일로 등록하십시오. Op 등록은 op의 구현과 독립적인 op 기능을위한 인터페이스를 정의합니다. 예를 들어 op 등록은 op의 이름과 op의 입력과 출력을 정의합니다. 또한 텐서의 모양을 정의합니다. C ++로 op의 실제 동작을 구현하십시오. op의 구현은 커널로 알려져 있으며 1 단계에서 등록한 인터페이스의 구체적인 구현입니다.(실제 연산을 정의하라는 말) 다양한 입/출력 유형 또는 아키텍처 (예 : CPU, GPU)에 대해 여러 개의 커널이있을 수 있습니다. Python 래퍼를 만듭니다 (선택 사항). 이 래퍼는 Python에서 op를 만드는 데 사용되는 공용 API입니다. op 등록에서 기본 래퍼가 생성됩니다.이 래퍼는 직접 사용하거나 추가 할 수 있습니다. op (옵션)의 gradient를 계산하는 함수를 작성합니다. op를 테스트하십시오. 우리는 대개 편의상 Python에서 이 작업을 수행하지만 C++로 op를 테스트 할 수도 있습니다. Gradient를 정의하면 파이썬 gradient checker로 확인할 수 있습니다. relu_op_test.pyRelu를 보면 Relu-like operators의 forward함수와 그들의 gradient를 확인할 수 있습니다. op의 인터페이스 정의op의 인터페이스는 TensorFlow 시스템에 등록하여 정의합니다.등록시 op의 이름, 입력 (유형 및 이름) 및 출력 (유형 및 이름)과 op가 필요할 수 있는 docstrings 및 attrs를 지정합니다.이것이 어떻게 작동 하는지를보기 위해 예시를 들어보겠습니다.int32 형태의 첫 번째 요소를 제외한 모든 요소가 0으로 되는 텐서 복사본을 출력 하는 op를 만들고 싶다고 가정합니다.이렇게하려면 명명 된 파일을 만듭니다 zero_out.cc.그런 다음 REGISTER_OP사용자 인터페이스에 대한 인터페이스를 정의하는 매크로 호출을 추가 하십시오.~tensorflow/core/user_ops 에 파일을 만들었습니다.123456789101112#include &quot;tensorflow/core/framework/op.h&quot;#include &quot;tensorflow/core/framework/shape_inference.h&quot;using namespace tensorflow;REGISTER_OP(&quot;ZeroOut&quot;) .Input(&quot;to_zero: int32&quot;) .Output(&quot;zeroed: int32&quot;) .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) &#123; c-&gt;set_output(0, c-&gt;input(0)); return Status::OK(); &#125;); 이 ZeroOut연산은 하나의 텐서 to_zero32 비트 정수를 입력으로 취해서 텐서 32 비트 정수 zeroed을 출력합니다.op는 출력 텐서가 입력 텐서와 동일한 모양인지 확인하기 위해 shape 함수를 사용합니다.예를 들어, 입력이 텐서 형태 [10, 20]이면이 모양 함수는 출력 모양도 [10, 20]으로 지정합니다. 이름 지정에 대한 참고 사항 : op 이름은 CamelCase여야하며 binary file에 등록된 다른 모든 운영 체제 중에서 고유해야합니다. op의 kernel코드 작성인터페이스를 정의한 후에 op의 하나 이상의 구현을 제공하십시오.커널을 만드려면 OpKernel을 확장하는 클래스를 만들어야합니다.그리고 Compute method를 오버라이드 해야합니다.Compute메서드는 OpKernelContext* type의 context 인수를 하나 제공합니다.이 인수를 사용하여 입력 및 출력 텐서와 같은 유용한 항목에 액세스 할 수 있습니다.위에 작성한 파일에 커널을 추가하십시오. 커널은 다음과 같이 생겼습니다.1234567891011121314151617181920212223242526272829#include &quot;tensorflow/core/framework/op_kernel.h&quot;using namespace tensorflow;class ZeroOutOp : public OpKernel &#123; public: explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) &#123;&#125; void Compute(OpKernelContext* context) override &#123; // Grab the input tensor const Tensor&amp; input_tensor = context-&gt;input(0); auto input = input_tensor.flat&lt;int32&gt;(); // Create an output tensor Tensor* output_tensor = NULL; OP_REQUIRES_OK(context, context-&gt;allocate_output(0, input_tensor.shape(), &amp;output_tensor)); auto output = output_tensor-&gt;flat&lt;int32&gt;(); // Set all but the first element of the output tensor to 0. const int N = input.size(); for (int i = 1; i &lt; N; i++) &#123; output(i) = 0; &#125; // Preserve the first input value if possible. if (N &gt; 0) output(0) = input(0); &#125;&#125;; 커널을 구현 한 후에는 TensorFlow 시스템에 등록하십시오.등록시 이 커널이 실행될 다른 제약 조건을 지정합니다.예를 들어, CPU 용으로 만든 커널 하나와 GPU 용으로 만든 커널을 따로 가질 수 있습니다. 그리고 이것을 ZeroOut op가 하기 위해서 아래의 코드를 zero_out.cc 코드에 추가합니다.1REGISTER_KERNEL_BUILDER(Name(&quot;ZeroOut&quot;).Device(DEVICE_CPU), ZeroOutOp); op라이브러리 빌드두가지 방법을 제시하고 있습니다.g++을 통한 방법과 bazel을 통한 방법인데요.bazel을 통한 빌드가 더 빠르다는 커뮤니티원의 정보를 듣고 bazel만으로 빌드를 진행했습니다. TensorFlow 소스가 설치되어있는 경우 TensorFlow의 빌드 시스템을 사용하여 작업을 컴파일 할 수 있습니다.디렉토리에 다음 Bazel 빌드 규칙이있는 BUILD 파일을 tensorflow/core/user_ops놓습니다.123456load(&quot;//tensorflow:tensorflow.bzl&quot;, &quot;tf_custom_op_library&quot;)tf_custom_op_library( name = &quot;zero_out.so&quot;, srcs = [&quot;zero_out.cc&quot;],) zero_out.so를 빌드하기 위해서는 아래의 명령어를 입력해주세요.1bazel build --config opt //tensorflow/core/user_ops:zero_out.so 참고 : .so표준 cc_library규칙 을 사용하여 공유 라이브러리(파일)를 만들 수 있지만 tf_custom_op_library매크로를 사용하는 것이 좋습니다. 몇 가지 필수 종속성을 추가하고 공유 라이브러리가 TensorFlow의 플러그인로드 메커니즘과 호환되는지 확인하기위한 검사를 수행합니다. 파이썬에서 op를 사용하기 위한 방법TensorFlow Python API는 tf.load_op_library동적 라이브러리를로드하고 op를 TensorFlow 프레임 워크에 등록하는 기능을 제공합니다.load_op_libraryop와 커널을 위한 파이썬 래퍼를 포함하는 파이썬 모듈을 리턴합니다.따라서 일단 op를 빌드하면 다음을 수행하여 Python에서 실행할 수 있습니다.1234567import tensorflow as tfzero_out_module = tf.load_op_library(&apos;zero_out.so&apos;)with tf.Session(&apos;&apos;): zero_out_module.zero_out([[1, 2], [3, 4]]).eval()# Printsarray([[1, 0], [0, 0]], dtype=int32) 참고로 snake_name case가 되기 때문에 op의 이름이 C++에서 ZeroOut이었다면, 파이썬에서는 zero_out이 됩니다. 테스트성공적으로 op를 구현했는지 확인하는 좋은 방법은 테스트를 작성하는 것입니다.다음 내용으로 zero_out_op_test.py 파일 을 만듭니다 .1234567891011import tensorflow as tfclass ZeroOutTest(tf.test.TestCase): def testZeroOut(self): zero_out_module = tf.load_op_library(&apos;zero_out.so&apos;) with self.test_session(): result = zero_out_module.zero_out([5, 4, 3, 2, 1]) self.assertAllEqual(result.eval(), [5, 0, 0, 0, 0])if __name__ == &quot;__main__&quot;: tf.test.main() 그런 다음 테스트를 실행하십시오 (tensorflow가 설치되어 있다고 가정).1python zero_out_op_test.py 그런데 이대로 되시나요??지금 op customizing 부분에 심각한 오류가 있는 것 같습니다.bazel을 이용해서 op customizing을 하는 부분은 현재 오류가 있어서 안되는 것 같더군요.그래서 g++로 다시 빌드를 해보았습니다.1234# 홈디렉토리에서TF_INC=$(python -c &apos;import tensorflow as tf; print(tf.sysconfig.get_include())&apos;)# tensorflow/tensorflow/core/uer_ops 경로에서g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC -I $TF_INC -O2 자, 이렇게 빌드를 했더니 zero_out.so 파일이 해당 경로에 생겼습니다.다시 파일로 돌아갔습니다.그리고 path를 잘 못알아들어서 수동으로 다시 코드를 짜주었습니다.12345import os.pathimport tensorflow as tfzero_out_module = tf.load_op_library(&apos;zero_out.so가 있는 경로 전부 루트부터 입력&apos;)sess = tf.Session()print (sess.run(zero_out_module.zero_out([[1,2], [3,4]]))) 자, 이제 정상 작동을 합니다. 이것으로 user customizing op를 텐서플로우에 추가하는 방법에 대한 설명을 마치겠습니다.","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"Internal","slug":"Tensorflow/Internal","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/Internal/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"internal","slug":"internal","permalink":"https://deeptensorflow.github.io/tags/internal/"},{"name":"build","slug":"build","permalink":"https://deeptensorflow.github.io/tags/build/"}]},{"title":"텐서플로우 내부 구조에 대해 알아보자","slug":"tensorflow-architecture-feature","date":"2017-02-21T06:33:44.000Z","updated":"2017-02-21T12:24:46.000Z","comments":true,"path":"2017/02/21/tensorflow-architecture-feature/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/21/tensorflow-architecture-feature/","excerpt":"","text":"본 내용은 https://www.tensorflow.org/extend/architecture 공홈의 내용을 번역한 것입니다. 텐서플로우의 내부는 어떻게 생겼을까?요런식으로 생겼습니다.주목해야할 점들은 다음과 같습니다. 클라이언트(tensorflow로 코드를 작성하는 부분) 계산을 data flow graph으로 정의 세션을 사용하여 그래프 실행 Distributed Master Session.run ()의 인수로 사용된 특정부분의 그래프를 정리 하위 그래프를 다른 프로세스와 장치에서 실행되는 여러 조각으로 분할 그래프 조각을 worker에 뿌림 worker service 사용 가능한 하드웨어 (CPU, GPU 등)에 적합한 커널 구현을 사용하여 그래프 작업 스케줄링 가능 다른 작업자 서비스와 작업 결과를 송수신 커널 구현 개별 그래프에 대한 연산 수행 대략적인 워크 플로우 그래프저 위의 그림에서 MASTER는 분산 프로그래밍된 TensorFlow에만 존재합니다.Tensorflow가 단일버전으로 이루어져있다면 마스터가하는 모든 작업을 수행하지만 로컬 프로세스의 장치와만 통신하는 특수 세션 구현이 포함됩니다. 클라이언트에서 일어나는 일사용자는 계산 그래프를 작성하는 클라이언트 TensorFlow 프로그램을 작성합니다.여러 라이브러리들을 써서 작업할수도 있으며 여러 layer들을 구성해 가며 추상화 작업을 진행합니다.TensorFlow는 Python과 C++언어를 지원합니다. Distributed master에서 일어나는 일그래프를 분할하는 작업을 합니다.이렇게 분할된 그래프에 분산 노드간에 정보를 전달하기 위해 송수신 노드를 삽입합니다그리고는 task에게 일을 전달하는 것입니다.이런식으로 텐서플로우에서는 코드를 병렬적으로 빠르게 수행할 수가 있습니다. Worker가 하는 일 마스터로부터 온 일을 처리함 연산에 대한 커널의 실행들을 스케줄링함 작업간의 직접적인 통신 역할(한쪽이 죽으면 그 일을 다른곳에 넘긴다던지..)Worker는 커널을 로컬 장치에 디스패치하고 가능하면 다중 CPU 코어 또는 GPU 스트림을 사용하여 병렬로 커널을 실행합니다. 즉 Worker는 장치 유형의 각 쌍에 대해 Send 및 Recv 작업을 전문적으로 수행합니다.1) CPU와 CPU 끼리는 cudaMemcpyAsync() API를 사용하여 계산 및 데이터 전송을 중첩합니다.2) CPU와 GPU 끼리는 값 비싼 복사를 피하기 위해 peer to peer DMA를 사용합니다. 작업간 전송의 경우 tensorflow는 다음의 프로토콜을 사용합니다.1) TCP를 통한 gRPC2) 수렴형 이더넷을 통한 RDMA 또한 다중 GPU 통신을위한 NVIDIA의 NCCL 라이브러리에 대한 예비 지원을 받았습니다. 커널 구현런타임에는 수학, 배열 조작, 제어 흐름 및 상태 관리 작업을 포함하여 200 개가 넘는 표준 작업이 포함됩니다.각 작업들은 각 device에 맞게 최적화시킬 수 있습니다.많은 운영 커널은 Eigen :: Tensor를 사용하여 구현되며, C ++ 템플릿을 사용하여 멀티 코어 CPU 및 GPU를위한 효율적인 병렬 코드를 생성합니다.그러나 우리는보다 효율적인 커널 구현이 가능한 cuDNN과 같은 라이브러리를 자유롭게 사용합니다.우리는 또한 모바일 장치 및 고처리량 데이터센터 응용프로그램과 같은 환경에서 더 빠른 추론을 가능하게하는 quantization을 구현했으며 quantum 연산을 가속화하기 위해 gemmlowp low-precision matrix library 를 사용합니다.하위 연산을 연산 조합으로 나타 내기가 어렵거나 비효율적 인 경우 사용자는 C ++로 작성된 효율적인 구현을 제공하는 추가 커널을 등록 할 수 있습니다.","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"Internal","slug":"Tensorflow/Internal","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/Internal/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"internal","slug":"internal","permalink":"https://deeptensorflow.github.io/tags/internal/"}]},{"title":"텐서플로우 빌드하는 방법 (텐서플로우에 내코드 추가하기)","slug":"how-to-build-tensorflow-with-pip","date":"2017-02-21T00:47:00.000Z","updated":"2017-02-21T01:25:59.000Z","comments":true,"path":"2017/02/21/how-to-build-tensorflow-with-pip/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/21/how-to-build-tensorflow-with-pip/","excerpt":"","text":"직접 bazel로 빌드했을때의 장점?tensorflow 커뮤니티에 올라온 정보들에 따르면 직접 빌드했을때 속도가 소폭 향상된다고 합니다.추후 직접 실험을 해서 속도비교를 해서 올릴 예정입니다.그리고 자신이 직접 내부의 소스코드를 수정해서 빌드하면 ‘나만의 텐서플로우’를 만들 수 있습니다. 빌드 전 개발환경 세팅pip(파이썬 패키지 매니저)과 java-jdk가 설치되어 있어야 합니다.설치 방법은 OS환경마다 다르지만 매우 간단합니다.아마 대부분 설치가 이미 되어있을 것이라고 생각하기 때문에 그냥 넘어가겠습니다. bazel 다운로드https://bazel.build/ 에서 다운로드가 가능합니다.curl로 다운 받는 방법은 아래와 같습니다.12345678910export BAZELRC=/home/&lt;yourid&gt;/.bazelrcexport BAZEL_VERSION=0.4.2mkdir /home/&lt;yourid&gt;/bazelcd /home/&lt;yourid&gt;/bazelcurl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.shcurl -fSsL -o /home/&lt;yourid&gt;/bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE.txtchmod +x bazel-*.shsudo ./bazel-$BAZEL_VERSION-installer-linux-x86_64.shcd /home/&lt;yourid&gt;/rm -f /home/&lt;yourid&gt;/bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh tensorflow github에서 다운로드소스가 있어야 빌드를 하겠죠?그리고 wheel, six, numpy 패키지가 필요합니다.123456git clone https://github.com/tensorflow/tensorflowcd tensorflowgit checkout r1.0 #빌드를 원하는 버전을 입력하시면 되요.sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel #ubuntu 쓰는 분들만brew install python3 #맥 쓰는 분들만sudo pip3 install six numpy wheel #맥쓰는 분들만 여기서 빌드를 하기 전에 소스코드를 고쳐서 텐서플로우에 내 소스를 추가할 수 있습니다.공식 홈페이지에서 해당 내용도 있습니다.https://www.tensorflow.org/extend/adding_an_op다음 포스팅으로 자세히 해당 내용에 대해서도 다루어 보겠습니다. tensorflow에서는 설정을 쉽게 하는 방법을 제공합니다.tensorflow 폴더에서 ./configure 하시면 빌드 설정을 쉽게 하도록 도와줍니다.12345678910111213141516171819202122232425262728293031323334353637$ cd tensorflow # cd to the top-level directory created$ ./configurePlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n]jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N]No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]No XLA JIT support will be enabled for TensorFlowFound possible Python library paths: /usr/local/lib/python2.7/dist-packages /usr/lib/python2.7/dist-packagesPlease input the desired Python library path to use. Default is [/usr/local/lib/python2.7/dist-packages]Using python library path: /usr/local/lib/python2.7/dist-packagesDo you wish to build TensorFlow with OpenCL support? [y/N] NNo OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N] YCUDA support will be enabled for TensorFlowPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: &quot;3.5,5.2&quot;]: 3.0Setting up Cuda includeSetting up Cuda libSetting up Cuda binSetting up Cuda nvvmSetting up CUPTI includeSetting up CUPTI lib64Configuration finished 중간에 파이썬 버전 선택이나 CUDA 지원 여부 자신의 환경에 맞게 잘 세팅해주세요.제안들이 친절하게 분류되어있어서 어려움은 없을 것 같습니다. bazel로 빌드하기설정이 끝났다면 빌드를 해야겠죠?12bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package #cpu버전일경우bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package #gpu버전일 경우 pip 패키지로 관리하기 쉽게 만들어줍시다.1bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg pip으로 다운받아줍시다.12sudo pip install /tmp/tensorflow_pkg/tensorflow-1.0.0-py2-none-any.whl #python2버전sudo pip3 install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp36-cp36m-macosx_10_12_x86_64.whl #python3버전 이건 설정에 따라서 다르닌깐요sudo pip(파이썬3이면 pip3) install /tmp/tensorflow_pkg/ 한다음에 tab키 쳐주시면 뜨는데 그리고 엔터 눌러주세요.","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"Internal","slug":"Tensorflow/Internal","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/Internal/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"internal","slug":"internal","permalink":"https://deeptensorflow.github.io/tags/internal/"},{"name":"build","slug":"build","permalink":"https://deeptensorflow.github.io/tags/build/"}]},{"title":"시그모이드 함수는 왜 쓰일까? logistic regression, softmax regression","slug":"why-use-sigmoid-and-what-is-logistic-classification","date":"2017-02-19T09:08:56.000Z","updated":"2017-02-19T11:38:40.000Z","comments":true,"path":"2017/02/19/why-use-sigmoid-and-what-is-logistic-classification/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/19/why-use-sigmoid-and-what-is-logistic-classification/","excerpt":"","text":"시그모이드 함수란?그림 실력 지못미 ㅠㅠ위의 그림처럼 생긴 함수입니다.0과 1 사이에서 값이 정해진다는 것만 유심히 보시면 됩니다.linear regression을 지난번 포스팅에서 y = W * X + b의 꼴로 설명드렸지요?(https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/)이러한 꼴로는 해석하기 힘든 현상들이 있어서 나온 것이 바로 logistic regression이고 여기서 쓰이는 함수가 sigmoid 함수입니다. logistic regression이 나오게 된 계기를 먼저 알자이전 포스팅에서 다룬 linear regression을 적용하기 힘든 부분은 바로 true of flase 꼴을 처리할 때입니다.왜 처리하기가 힘드냐? 기본적으로 y = ax + b 꼴의 선형 함수는 우선 x에 따른 대응되는 y값이 무한대입니다.0과 1로 처리를 하고싶은 logistic classification의 경우 적용하기 무리가 있지요.0 아니면 1, true 아니면 flase, 모 아니면 도 이런 경우이지요.현실의 예를 들자면 스팸메일인지 아닌지, 합격인지 불합격인지가 이런 경우에 해당됩니다.그래서 이를 대체할 함수를 찾다가! 딱! 시그모이드 함수를 발견하게 된 것입니다.그리고 시그모이드 함수를 기존의 linear regression에 그대로 씌워봤는데 효과가 좋아서 이것을 logistic regression이라고 하게 된 것이지요.기본적으로 0과 1사이에서 값이 노는데다가 0.5 기준점으로 원점대칭 꼴이라서 코드 적용도 쉽습니다.기존의 linear regression ax+b의 부분을 시그모이드 함수의 x부분에 넣어주었더니 실제로 양자택일의 경우에 굉장히 뛰어난 효율을 보여줬습니다.(1/(1+e^(-(ax+b))))현재도 정말 유용하게 쓰이고 있는 함수 모델입니다. 그냥 바로 코드에 적용시켜도 되나요?sigmoid 를 이용한 logistic classification 코드를 작성하는 방법을 설명해주는 강의가 있습니다.요약하자면 cost함수를 구성할때 그대로 적용하면 굴곡진 부분들이 많아져서 gradient descent 알고리즘 적용에는 무리가 있으니 log함수를 취해줘서 그래프를 펴주자… 이런 내용입니다.꼭 한번 강의를 듣는 것을 추천드립니다.홍콩 과기대의 김성훈 교수님의 강의입니다. softmax regression 이라는 것도 있던데…이것은 그냥 logistic regression을 muti-variable 형식으로 구성한 것이라고 보면 됩니다.예를 들어 표현해 보도록 하겠습니다.기존의 logistic regression은 양자택일을 해주었죠?그리고 그것을 돕는 함수가 sigmoid 함수였습니다.이것을 한번 응용해 보도록 하겠습니다.A학점 B학점 C학점이 있다고 가정하겠습니다.공부하는 시간에 따른 학점이 얼마나 나오는지 알아보고 싶습니다.공부하는 시간을 X라고 두면 이에 따른 weight와 bias가 있을 것입니다.대충 Y = W * X + b 꼴이 될 것입니다.여기에 우리가 배운 logistic regression을 적용하면 시그모이드가 씌워져서 0~1사이의 값이 나오겠죠?이게 A학점, B학점, C학점에 대해 각각 따로따로 있는 것입니다.각 학점에 대한 bias와 weight를 둡니다.그리고 이것을 sigmoid를 씌워서 0~1사이의 값으로 나오게 하고 각 값들의 합을 1로 하여 확률로 변환하는 과정 까지를 softmax regression이라고 합니다.그리고 cost함수를 짜겠죠?(log함수를 이용합니다. 위의 유투브 영상에 짜는 방법 나옴!)실제 값을 출력할 때에는 argmax를 이용해서 가장 확률이 높은 값을 뽑습니다.","categories":[{"name":"Machinelearning","slug":"Machinelearning","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/"},{"name":"News","slug":"Machinelearning/News","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/News/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"https://deeptensorflow.github.io/tags/machinelearning/"},{"name":"algorithm","slug":"algorithm","permalink":"https://deeptensorflow.github.io/tags/algorithm/"}]},{"title":"선형회귀란 무엇을까? 텐서플로우를 통해 알아보자(linear regression)","slug":"what-is-linear-regression-with-tensorflow","date":"2017-02-19T04:44:28.000Z","updated":"2017-02-19T06:22:35.000Z","comments":true,"path":"2017/02/19/what-is-linear-regression-with-tensorflow/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/19/what-is-linear-regression-with-tensorflow/","excerpt":"","text":"선형회귀(linear regression) 위키백과 선형회귀란 종속 변수 y와 한 개 이상의 독립 변수 (또는 설명 변수) X와의 선형 상관 관계를 모델링하는 회귀분석 기법입니다.한 개의 설명 변수에 기반한 경우에는 단순 선형 회귀, 둘 이상의 설명 변수에 기반한 경우에는 다중 선형 회귀라고 합니다. 쉽게 설명하자면… 어떤사람은 2시간 공부해서 시험점수를 30점을 받았습니다.어떤사람은 3시간 공부해서 40점을, 어떤사람은 4시간 공부해서 50점을 받았습니다.이럴 경우에 공부시간과 시험점수 사이에 어떤 관계가 있는지 알아보고 싶겠죠?이럴 때 자주 쓰이는 기법이 선형 회귀입니다.그리고 더 세분화 하자면 결과에 미치는 요인이 한개이기 때문에 단순 선형 회귀라고 부릅니다.단순한 공부시간 뿐만 아니라 학교의 출석율도 한번 설명 변수로 넣어보겠습니다.어떤 사람은 2시간을 공부하고 학교에 5번 출석을 해서 20점을 받았습니다.어떤 사람은 2시간을 공부하고 학교에 10번을 출석해서 30점을 받았구요!어떤 사람은 5시간을 공부하고 학교에 20번을 출석해서 50점을 받았다고 가정하겠습니다.공부시간, 학교 출석율이 시험점수에 얼마나 영향을 미치는지 궁금하죠?이럴때 자주 쓰이는 기법이 선형 회귀입니다.더 세분화 하자면 설명 변수가 둘 이상이니 다중 선형 회귀라고 합니다. 방정식으로 알아보자 위의 경우에 아래의 방정식이 세워지죠?Y(시험점수) = x1(공부한시간) w1(공부시간과 시험점수의 상관계수) + x2(학교 출석율) w2(학교 출석율과 시험점수의 상관계수) + b(보정값)요약하자면 Y = x1w1 +x2w2 + b 입니다.중학교 때 많이 본 함수이지요?이런 모델을 써서 설명변수(x1, x2)와 종속변수(Y)의 상관관계를 알고자 하는 방법인 것입니다. 텐서플로우로 단순 선형 회귀에 대해 알아보자 일부러 상관관계를 알기 쉽도록 눈에 보이는 모델을 써봤습니다.공부시간이 1, 2, 3시간일때 시험 점수가 2, 4, 6점이라면?Y = x1*w1 + b의 모델이 짜질 것입니다.그리고 w1은 2, b는 0이 되어야 주어진 방정식을 만족할 것이라는 것을 우리는 알 수 있죠.한번 텐서플로우 코드로 확인해 보겠습니다. tf_linear_regression12345678910111213141516171819202122232425262728293031323334353637383940414243# 텐서플로우를 사용할 것을 알려줍니다.import tensorflow as tf# x_data는 공부시간, y_data는 시험성적 입니다.x_data = [1, 2, 3]y_data = [2, 4, 6]# W는 설명변수, b는 보정값 입니다.W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))# placeholder를 사용하면 변수의 형태만 지정해주고 나중에 값을 넣어줘도 됩니다.X = tf.placeholder(tf.float32)Y = tf.placeholder(tf.float32)# 방정식 모델입니다.hypothesis = W * X + b# cost 함수입니다. 뒤어서 설명하겠습니다.cost = tf.reduce_mean(tf.square(hypothesis - Y))# Gradient Descent 또한 뒤에서 설명하겠습니다.a = tf.Variable(0.1)optimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost)# 변수들을 초기화합니다.init = tf.global_variables_initializer()# 텐서플로우를 시작하게 하는 구문이라고 보시면 됩니다. 세션을 지정해줍니다.sess = tf.Session()sess.run(init)# X에 x_data를, Y에 y_data를 넣어서 2001번 소스를 돌려가며 W와 b값을 찾아갑니다.for step in range(2001): sess.run(train, feed_dict=&#123;X: x_data, Y: y_data&#125;) if step % 200 == 0: print(step, sess.run(cost, feed_dict=&#123;X: x_data, Y: y_data&#125;), sess.run(W), sess.run(b))# 5시간 공부했을때와 2.5시간 공부했을 때 몇점이 나올지 출력해봅니다.print(sess.run(hypothesis, feed_dict=&#123;X: 5&#125;))print(sess.run(hypothesis, feed_dict=&#123;X: 2.5&#125;)) 결과입니다. 12345678910111213141516# 순서대로 몇번째 트레이닝인지, 오차범위, W값, b값 입니다.0 0.245183 [ 2.28380156] [-0.13001066]200 3.87879e-07 [ 2.00072336] [-0.00164423]400 2.25526e-11 [ 2.00000548] [ -1.27652002e-05]600 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]800 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]1000 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]1200 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]1400 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]1600 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]1800 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]2000 1.51582e-13 [ 2.00000072] [ -1.24958285e-06]# 5시간 공부했을 때와 2.5시간 공부했을 때를 출력해줍니다.[ 10.00000286][ 5.00000048] cost 함수 &amp; gradient descent란? 김성훈 교수님의 강의가 이것을 이해하는데는 최고 같습니다.아래의 비디오 두편만 보면 이해가 빡! 다중 선형 회귀 함수는 어떻게 처리를 할까요? 다중 선형 회귀함수를 보기 좋게 처리하려면 한가지 아이디어가 필요합니다.행렬의 아이디어가 필요한데요.Y = X1W1 + X2W2 + X3W3 + …. + b 이런 꼴이 선형 회귀 모델인데요.이것을 어떻게 간결하게 표현할 방법이 없을까요?있습니다!Y = X1W1 + X2W2 + X3W3 +… + 1*b의 꼴로 두면 됩니다.그리고 이것을 행렬로 변환!요런식으로 행렬로 관리하면 되겠죠?(아, b1, b2, … bn은 전부 같은 값입니다.)그런데 더 간략하게 하고 싶다면 b까지 행렬에 포함시킬 수 있습니다.이럴경우에 코드는 어떻게 되냐구요? 다중 선형 회귀 함수 텐서플로우 예시 코드 12345678910111213141516171819202122232425import tensorflow as tfx_data = [[1., 2., 5.],[1., 3., 7.], [1., 4., 10.], [1., 7., 12.]]y_data = [1., 2., 3., 4.]W = tf.Variable(tf.random_uniform([3,1], -1, 1))# 이거 한줄로 가설함수 끝!hypothesis = tf.matmul(x_data, W)cost = tf.reduce_mean(tf.square(hypothesis - y_data))a = tf.Variable(0.01) # learning rate, alphaoptimizer = tf.train.GradientDescentOptimizer(a)train = optimizer.minimize(cost) # goal is minimize costinit = tf.global_variables_initializer()sess = tf.Session()sess.run(init)for step in range(2001): sess.run(train) if step % 200 == 0: print (step, sess.run(cost), sess.run(W)) 다중 선형 회귀를 이용했는데도(W 2개 b 1개) hypothesis 함수 코드가 엄청 간결하죠?행렬의 위력입니다~ (다들 선형대수 열공을..)참고로 x_data와 y_data에는 별다른 의미 없는 값을 넣었습니다.그냥 소스코드 참고용이라… ㅎ 결론은?linear regression이 대략적으로 어떤 요인에 미치는 변수들의 패턴을 선형적으로 파악하고자 하는 것이고 tensorflow를 이용하면 쉽게 구현이 가능하다!","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"App","slug":"Tensorflow/App","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/App/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"linearregression","slug":"linearregression","permalink":"https://deeptensorflow.github.io/tags/linearregression/"}]},{"title":"텐서플로우1.0 설치시 일어나는 기본 오류를 잡아보자 (bazel로 소스코드 빌드)","slug":"how-to-handle-tensorflow1-error","date":"2017-02-19T03:23:03.000Z","updated":"2017-02-21T00:02:31.000Z","comments":true,"path":"2017/02/19/how-to-handle-tensorflow1-error/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/19/how-to-handle-tensorflow1-error/","excerpt":"","text":"텐서플로우 1.0을 pip으로 설치하고 사용하면 일어나는 오류tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn’t compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations. 이런 오류를 보신적이 없으신가요?텐서플로우1.0을 pip(pip3)으로 설치하면 생기는 오류입니다.간단한 방법으로 (하지만 시간이 조금 걸리는 방법) 해결할 수 있습니다. bazel을 설치하자bazel은 구글에서 만든 빌드 툴입니다.https://bazel.build/ 에서 다운로드가 가능합니다.apt-get이나 homebrew 를 통해서도 설치가 가능하구요~자 설치가 끝났으면 텐서플로우 소스코드를 직접 빌드해보겠습니다. 예) 1234567891011export BAZELRC=/home/&lt;yourid&gt;/.bazelrcexport BAZEL_VERSION=0.4.2mkdir /home/&lt;yourid&gt;/bazelcd /home/&lt;yourid&gt;/bazelcurl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.shcurl -fSsL -o /home/&lt;yourid&gt;/bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE.txtchmod +x bazel-*.shsudo ./bazel-$BAZEL_VERSION-installer-linux-x86_64.shcd /home/&lt;yourid&gt;/rm -f /home/&lt;yourid&gt;/bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh 텐서플로우 소스코드 빌드하는 방법 텐서플로우 소스코드를 깃허브에서 받은 다음에 python3, numpy, wheel, six를 pip을 통해 받습니다. 123456git clone https://github.com/tensorflow/tensorflowcd tensorflowgit checkout r1.0 #빌드를 원하는 버전을 입력하시면 되요.sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel #ubuntu 쓰는 분들만brew install python3 #맥 쓰는 분들만sudo pip3 install six numpy wheel #맥쓰는 분들만 GPU 쓰실 분들은 아래의 명령어도 터미널에서 입력해주세요. 저는 PC에 GPU가 안달려있어서 테스트를 못해봤네요.조만간 GPU를 달 계획입니다!그런데 아마 오류는 없을거에요.123sudo apt-get install libcupti-dev #ubuntu 쓰는 분들만brew install coreutils #맥쓰는 분들만sudo xcode-select -s /Application/Xcode-7.2/Xcode.app #맥쓰는 분들만 configure를 해봅시다. tensorflow.org code12345678910111213141516171819202122232425262728293031323334353637$ cd tensorflow # cd to the top-level directory created$ ./configurePlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python2.7Please specify optimization flags to use during compilation when bazel option &quot;--config=opt&quot; is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n]jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N]No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]No XLA JIT support will be enabled for TensorFlowFound possible Python library paths: /usr/local/lib/python2.7/dist-packages /usr/lib/python2.7/dist-packagesPlease input the desired Python library path to use. Default is [/usr/local/lib/python2.7/dist-packages]Using python library path: /usr/local/lib/python2.7/dist-packagesDo you wish to build TensorFlow with OpenCL support? [y/N] NNo OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N] YCUDA support will be enabled for TensorFlowPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: &quot;3.5,5.2&quot;]: 3.0Setting up Cuda includeSetting up Cuda libSetting up Cuda binSetting up Cuda nvvmSetting up CUPTI includeSetting up CUPTI lib64Configuration finished 특별히 신경써야할 부분은 처음에 나오는 이부분들입니다. 1Please specify the location of python. [Default is /usr/bin/python]: (설정할 파이썬 path) 1Do you wish to build TensorFlow with CUDA support? Y(gpu 쓰실 분들은 y해야겠죠~) 잘 모르시겠으면 그냥 다 N 누르면서 진행하시면 원래 쓰시던 tensorflow 나올거에요~영어 잘하시면 직접 해석하시면서 설정을 해주세요. ㅎㅎ bazel로 빌드하기 12bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package #cpu버전일경우bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package #gpu버전일 경우 패키지화하기 1bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg pip 패키지 설치하기 12sudo pip install /tmp/tensorflow_pkg/tensorflow-1.0.0-py2-none-any.whl #python2버전sudo pip3 install /tmp/tensorflow_pkg/tensorflow-1.0.0-cp36-cp36m-macosx_10_12_x86_64.whl #python3버전 이건 설정에 따라서 다르닌깐요sudo pip(파이썬3이면 pip3) install /tmp/tensorflow_pkg/ 한다음에 tab키 쳐주시면 뜨는데 그리고 엔터 눌러주세요. 끝!이제 끝났습니다.이제 저런 오류없이 텐서플로우가 작동할 것입니다.긴 글 읽어주셔서 고맙습니다.https://www.tensorflow.org/install/install_sources 를 참고하여 작성한 문서입니다.","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"App","slug":"Tensorflow/App","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/App/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"install","slug":"install","permalink":"https://deeptensorflow.github.io/tags/install/"},{"name":"bazel","slug":"bazel","permalink":"https://deeptensorflow.github.io/tags/bazel/"}]},{"title":"최고의 머신러닝, 텐서플로우 초보용 무료강의를 소개합니다.","slug":"sung-hun-kim-ml-lecture","date":"2017-02-18T12:49:50.000Z","updated":"2017-02-18T12:56:40.000Z","comments":true,"path":"2017/02/18/sung-hun-kim-ml-lecture/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/18/sung-hun-kim-ml-lecture/","excerpt":"","text":"머신러닝이 무엇인지 모른다면?이전 포스팅을 봐주세요. 최고의 입문용 강의를 소개합니다.홍공 과기대의 김성훈 교수님이 진행하는 “모두를 위한 머신러닝과 딥러닝 강의”를 소개합니다.입문용 강의로는 정말 최고라고 생각됩니다.머신러닝에 대한 기초 알고리즘부터 텐서플로우로 응용까지 자세히 설명해 주셨습니다.수학이나 프로그래밍에 대한 기초가 없어도 편하게 들을 수 있습니다.(단, 파이썬은 아주 약간은 알아야 합니다.)파이썬을 아예 모르신다면 https://wikidocs.net/book/1 에서 무료로 공부하시는 것을 추천드립니다.자, 시범 강의 하나만 띄우겠습니다.매우 재미있겠지요?아주 쉽게 차근차근 잘 설명해주시니 기초지식이 없어도 두려워하지 마세요.https://hunkim.github.io/ml/ 로 가면 김성훈 교수님의 모든 강의를 무료로 볼 수 있습니다.","categories":[{"name":"Machinelearning","slug":"Machinelearning","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/"},{"name":"Lecture","slug":"Machinelearning/Lecture","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/Lecture/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"https://deeptensorflow.github.io/tags/machinelearning/"},{"name":"lecture","slug":"lecture","permalink":"https://deeptensorflow.github.io/tags/lecture/"}]},{"title":"왜 머신러닝은 주목받을까? 머신러닝이 무엇인지 알아보자.","slug":"why-machinelearning-is-appeared","date":"2017-02-18T12:15:56.000Z","updated":"2017-02-19T03:52:48.000Z","comments":true,"path":"2017/02/18/why-machinelearning-is-appeared/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/18/why-machinelearning-is-appeared/","excerpt":"","text":"머신러닝이 세상에 나오게 된 계기본래 프로그래머들이 프로그래밍을 짜는 방법은 일일이 가르쳐주는 방식이었습니다.입력값이 0일때는 작동을 중지하고 입력값이 1일때는 작동을 시작하고 이런 방식이었죠.그러다가 프로그래머들은 다음과 같은 호기심이 생깁니다.“프로그램이 인간처럼 학습할 수 있을까?”많은 오류들을 거쳐(이 오류들을 해결하는 과정이 상당히 재밌는데 다음에 다루겠습니다.) 결국 기계를 인간처럼 학습시키는데 성공하게 되고 이러한 프로그래밍을 머신러닝이라고 부르게 됩니다. 머신러닝은 무엇이 좋은가?머신러닝의 장점은 인간처럼 행동할 수 있다는 것입니다.원래는 우리는 기계에게 수많은 rule들을 제시해가며 행동을 가르쳤습니다.하지만 인간을 떠올린다면 인간은 무엇이 착한일이고 무엇이 나쁜일인지 어떻게 알게 되었을까요?무슨 행동을 일단 해보고 혼나면 나쁜일, 칭찬을 들으면 착한일이라고 알지 않았을까요?머신러닝을 적용하면 기계도 마찬가지로 행동을 할 수 있게 됩니다.우선 시험 데이터를 모아서 정답 데이터와 비교를 해봅니다.이렇게 시험 학습된 기계는 따로 인간이 rule을 정해주지 않아도 다음부터는 데이터가 들어오면 알아서 학습한 내용을 바탕으로 행동을 할 수 있게 됩니다.예를들어 사진 판별, 언어번역, 자동운전 등을 생각해 봅시다.일일히 규칙들을 정해준다면 얼마나 복잡할까요?그리고 새로운 규칙들이 매번 생겨나는 경우들도 있지요.이러한 경우에 머신러닝을 도입하면 상당히 프로그래밍이 쉽고 정교하게 됩니다. 머신러닝의 미래현재 구글이 tensorflow를 발표하고 머신러닝 1등 라이브러리로 우뚝 섰습니다.텐서플로우로 인해서 프로그래밍을 모르는 일반인들도 한달정도만 공부를 해도 어느정도 머신러닝을 활용할 수 있게 되어 진입장벽이 매우 낮아졌습니다.그리고 현재 우리나라는 비교적 소극적이지만 미국, 중국에서는 고액 연봉을 제시하며 서로 머신러닝 관련 프로그래머들을 영입하고 있습니다.점점 머신러닝을 자신들의 제품에 도입하는 경우도 늘어가고 있지요.머신러닝의 미래는 밝습니다!그리고 누구나 머신러닝을 사용할 수 있습니다!","categories":[{"name":"Machinelearning","slug":"Machinelearning","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/"},{"name":"News","slug":"Machinelearning/News","permalink":"https://deeptensorflow.github.io/categories/Machinelearning/News/"}],"tags":[{"name":"machinelearning","slug":"machinelearning","permalink":"https://deeptensorflow.github.io/tags/machinelearning/"}]},{"title":"텐서플로우 1.0(최신버전) 설치하는 방법","slug":"install-tensorflow","date":"2017-02-18T09:56:35.000Z","updated":"2017-02-19T01:12:01.000Z","comments":true,"path":"2017/02/18/install-tensorflow/","link":"","permalink":"https://deeptensorflow.github.io/2017/02/18/install-tensorflow/","excerpt":"","text":"텐서플로우 설치텐서플로우 1.0버전이 출시되었습니다~API변동이 약간 있는 것으로 파악되며 앞으로 텐서플로우1.0을 분석하여 블로그를 작성해보도록 하겠습니다.텐서플로우 공식 홈페이지에서 권장하는 방식인 virtualenv로 설치하는 방법을 택하였습니다.virtualenv를 사용하면 다른 python 프로그램들에 간섭하거나 영향받는 일이 없어집니다. 텐서플로우 MAC 설치 homebrew 설치 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; homebrew는 mac의 패키지 관리자입니다. python3 설치 1brew install python3 virtualenv 설치 1pip3 install virtualenv virtualenv 환경 세팅(tensorflow 폴더) 123virtualenv tensorflowsource tensorflow/bin/activatecd tensorflow tensorflow 최신버전 설치(cpu버전) 1pip3 install --upgrade tensorflow tensorflow 최신버전 설치(gpu버전) 1pip3 install --upgrade tensorflow-gpu 설치에 실패한 경우 pip3 버전이 8.1이하인 경우일 것입니다.1brew upgrade python3해주시고 다시 처음부터 진행해 주시기 바랍니다. 가상환경을 종료하고 싶은경우 1deactivate 텐서플로우 LINUX 설치 python3 설치 1sudo apt-get install python3 virtualenv 설치 1pip3 install virtualenv virtualenv 환경 세팅(tensorflow 폴더) 123virtualenv tensorflowsource tensorflow/bin/activatecd tensorflow tensorflow 최신버전 설치(cpu버전) 1pip3 install --upgrade tensorflow tensorflow 최신버전 설치(gpu버전) 1pip3 install --upgrade tensorflow-gpu 설치에 실패한 경우 pip3 버전이 8.1이하인 경우일 것입니다. 1sudo apt-get upgrade python3 해주시고 다시 처음부터 진행해 주시기 바랍니다. 가상환경을 종료하고 싶은경우 1deactivate 텐서플로우 WINDOW 설치 python 3.5 설치 다른 운영체제와 다르게 3.6버전을 아직 지원하지 않으니 주의 바랍니다.https://www.python.org/downloads/release/python-352/위의 링크에서 3.5버전을 다운받으시기 바랍니다. tensorflow 최신버전 설치(cpu버전) 1pip3 install --upgrade tensorflow tensorflow 최신버전 설치(gpu버전) 1pip3 install --upgrade tensorflow-gpu","categories":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/"},{"name":"App","slug":"Tensorflow/App","permalink":"https://deeptensorflow.github.io/categories/Tensorflow/App/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://deeptensorflow.github.io/tags/tensorflow/"},{"name":"install","slug":"install","permalink":"https://deeptensorflow.github.io/tags/install/"}]}]}